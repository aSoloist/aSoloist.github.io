<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Mybatis Example 用法]]></title>
    <url>%2F2018%2F04%2F17%2FMybatis%20Example%20%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Example 类是什么Example类指定如何构建一个动态的where子句. 表中的每个non-BLOB列可以被包括在where子句中。例子是展示此类用法的最好方式。 Example类可以用来生成一个几乎无限的where子句. Example类包含一个内部静态类 Criteria 包含一个用 anded 组合在where子句中的条件列表. Example类包含一个 List 属性,所有内部类Criteria中的子句会用 ored组合在一起. 使用不同属性的 Criteria 类允许您生成无限类型的where子句. 创建 Criteria 对象 可以使用Example类中的 createCriteria() 或者 or() . 如果 Criteria 对象是用 createCriteria() 创建的，它会自动为 List 属性添加一个 Criteria 对象 - 这使得它更容易写一个简单的where子句， 如果您不需要 or 或者其他几个子句组合的话. 用 or(Criteria criteria) 方法创建 Criteria 对象, 方法里的 criteria 对象会被添加进 Criteria 对象的列表中. 重要 我们推荐您只使用 or() 方法创建 Criteria 对象. 我们相信这种方法使代码更有可读性. 如何生成Example类mybatis的的配置文件可以使用mybatis-generator工具生成，它就可以帮我们生成example类。 当我们需要生成example类的时候，只需要在配置文件的table里面去掉 123enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;false&quot;enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;false&quot;selectByExampleQueryId=&quot;false&quot; 如何使用Example简单查询这个例子展示了如何用生成后的Example类去生成一个简单的where子句: 12TableExample example = new TableExample();example.createCriteria().andFieldEqualTo(5); 作为另一种选择, 下面的方式也是可以的: 12TestTableExample example = new TestTableExample();example.or().andFieldEqualTo(5); 在上面的例子中, 动态生成的where子句是: where field = 5 复杂查询下面的例子展示了如何用生成后的Example类去生成一个复杂的where子句: 123456789101112131415161718192021TableExample example = new TableExample(); example.or() .andField1EqualTo(5) .andField2IsNull(); example.or() .andField3NotEqualTo(9) .andField4IsNotNull(); List field5Values = new ArrayList(); field5Values.add(8); field5Values.add(11); field5Values.add(14); field5Values.add(22); example.or() .andField5In(field5Values);example.or() .andField6Between(3, 7); 在上面的例子中, 动态生成的where子句是: where (field1 = 5 and field2 is null) or (field3 &lt;&gt; 9 and field4 is not null) or (field5 in (8, 11, 14, 22)) or (field6 between 3 and 7) 将会返回满足这些条件的记录结果. 去重复查询您可以在所有的Example类中调用 setDistinct(true) 方法进行强制去重复查询. Criteria类Criteria 内部类的每个属性都包含 andXXX 方法，以及如下的标准的SQL查询方法: IS NULL - 指相关的列必须为NULL IS NOT NULL - 指相关的列必须不为NULL = (equal) - 指相关的列必须等于方法参数中的值 &lt;&gt; (not equal) - 指相关的列必须不等于方法参数中的值 (greater than) - 指相关的列必须大于方法参数中的值 = (greater than or equal) - 指相关的列必须大于等于方法参数中的值 &lt; (less than) - 指相关的列必须小于于方法参数中的值 &lt;= (less than or equal) - 指相关的列必须小于等于方法参数中的值 LIKE - 指相关的列必须 “like” 方法参数中的值. 这个方法不用必须加入 ‘%’, 您必须设置方法参数中的值. NOT LIKE - 指相关的列必须 “not like” 方法参数中的值. 这个方法不用必须加入 ‘%’, 您必须设置方法参数中的值. BETWEEN - 指相关的列必须在 “between” 方法参数中的两个值之间. NOT BETWEEN - 指相关的列必须不在 “not between” 方法参数中的两个值之间. IN - 指相关的列必须在传入的方法参数的list中. NOT IN - 指相关的列必须不在传入的方法参数的list中. mapper中的实例函数int countByExample(UserExample example) thorws SQLException：按条件计数。 int deleteByExample(UserExample example) thorws SQLException：按条件删除。 int deleteByPrimaryKey(Integer id) thorws SQLException：按主键删除。 String/Integer insert(User record) thorws SQLException：插入(返回值为id值) String/Integer insertSelective(User record) throws SQLException：插入一条数据,只插入不为null的字段,不会影响有默认值的字段 List&lt;?&gt;selectByExample(UserExample example) thorws SQLException：按条件查询 User selectByPrimaryKey(Integer id) thorws SQLException：按主键查询。 int updateByExample(User record, UserExample example) thorws SQLException： 按条件更新 int updateByPrimaryKeySelective(User record) thorws SQLException：按主键更新值不为null的字段 int updateByExampleSelective(User record, UserExample example)thorws SQLException：按条件更新不为null的字段 int updateByPrimaryKey(User record) thorws SQLException：按主键更新 SQLException：按条件更新值不为null的字段]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis Example</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis Generator完整配置详解]]></title>
    <url>%2F2018%2F04%2F17%2FMybatis%20Generator%E5%AE%8C%E6%95%B4%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言转自Mybatis Generator最完整配置详解 用于自己以后需要重新配置Generator时使用。 配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN""http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"&gt;&lt;!-- 配置生成器 --&gt;&lt;generatorConfiguration&gt;&lt;!-- 可以用于加载配置项或者配置文件，在整个配置文件中就可以使用$&#123;propertyKey&#125;的方式来引用配置项 resource：配置资源加载地址，使用resource，MBG从classpath开始找，比如com/myproject/generatorConfig.properties url：配置资源加载地质，使用URL的方式，比如file:///C:/myfolder/generatorConfig.properties. 注意，两个属性只能选址一个; 另外，如果使用了mybatis-generator-maven-plugin，那么在pom.xml中定义的properties都可以直接在generatorConfig.xml中使用&lt;properties resource="" url="" /&gt; --&gt; &lt;!-- 在MBG工作的时候，需要额外加载的依赖包 location属性指明加载jar/zip包的全路径&lt;classPathEntry location="/Program Files/IBM/SQLLIB/java/db2java.zip" /&gt; --&gt; &lt;!-- context:生成一组对象的环境 id:必选，上下文id，用于在生成错误时提示 defaultModelType:指定生成对象的样式 1，conditional：类似hierarchical； 2，flat：所有内容（主键，blob）等全部生成在一个对象中； 3，hierarchical：主键生成一个XXKey对象(key class)，Blob等单独生成一个对象，其他简单属性在一个对象中(record class) targetRuntime: 1，MyBatis3：默认的值，生成基于MyBatis3.x以上版本的内容，包括XXXBySample； 2，MyBatis3Simple：类似MyBatis3，只是不生成XXXBySample； introspectedColumnImpl：类全限定名，用于扩展MBG--&gt;&lt;context id="mysql" defaultModelType="hierarchical" targetRuntime="MyBatis3Simple" &gt; &lt;!-- 自动识别数据库关键字，默认false，如果设置为true，根据SqlReservedWords中定义的关键字列表； 一般保留默认值，遇到数据库关键字（Java关键字），使用columnOverride覆盖 --&gt; &lt;property name="autoDelimitKeywords" value="false"/&gt; &lt;!-- 生成的Java文件的编码 --&gt; &lt;property name="javaFileEncoding" value="UTF-8"/&gt; &lt;!-- 格式化java代码 --&gt; &lt;property name="javaFormatter" value="org.mybatis.generator.api.dom.DefaultJavaFormatter"/&gt; &lt;!-- 格式化XML代码 --&gt; &lt;property name="xmlFormatter" value="org.mybatis.generator.api.dom.DefaultXmlFormatter"/&gt; &lt;!-- beginningDelimiter和endingDelimiter：指明数据库的用于标记数据库对象名的符号，比如ORACLE就是双引号，MYSQL默认是`反引号； --&gt; &lt;property name="beginningDelimiter" value="`"/&gt; &lt;property name="endingDelimiter" value="`"/&gt; &lt;!-- 必须要有的，使用这个配置链接数据库 @TODO:是否可以扩展 --&gt; &lt;jdbcConnection driverClass="com.mysql.jdbc.Driver" connectionURL="jdbc:mysql:///pss" userId="root" password="admin"&gt; &lt;!-- 这里面可以设置property属性，每一个property属性都设置到配置的Driver上 --&gt; &lt;/jdbcConnection&gt; &lt;!-- java类型处理器 用于处理DB中的类型到Java中的类型，默认使用JavaTypeResolverDefaultImpl； 注意一点，默认会先尝试使用Integer，Long，Short等来对应DECIMAL和 NUMERIC数据类型； --&gt; &lt;javaTypeResolver type="org.mybatis.generator.internal.types.JavaTypeResolverDefaultImpl"&gt; &lt;!-- true：使用BigDecimal对应DECIMAL和 NUMERIC数据类型 false：默认, scale&gt;0;length&gt;18：使用BigDecimal; scale=0;length[10,18]：使用Long； scale=0;length[5,9]：使用Integer； scale=0;length&lt;5：使用Short； --&gt; &lt;property name="forceBigDecimals" value="false"/&gt; &lt;/javaTypeResolver&gt; &lt;!-- java模型创建器，是必须要的元素 负责：1，key类（见context的defaultModelType）；2，java类；3，查询类 targetPackage：生成的类要放的包，真实的包受enableSubPackages属性控制； targetProject：目标项目，指定一个存在的目录下，生成的内容会放到指定目录中，如果目录不存在，MBG不会自动建目录 --&gt; &lt;javaModelGenerator targetPackage="com._520it.mybatis.domain" targetProject="src/main/java"&gt; &lt;!-- for MyBatis3/MyBatis3Simple 自动为每一个生成的类创建一个构造方法，构造方法包含了所有的field；而不是使用setter； --&gt; &lt;property name="constructorBased" value="false"/&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- for MyBatis3 / MyBatis3Simple 是否创建一个不可变的类，如果为true， 那么MBG会创建一个没有setter方法的类，取而代之的是类似constructorBased的类 --&gt; &lt;property name="immutable" value="false"/&gt; &lt;!-- 设置一个根对象， 如果设置了这个根对象，那么生成的keyClass或者recordClass会继承这个类；在Table的rootClass属性中可以覆盖该选项 注意：如果在key class或者record class中有root class相同的属性，MBG就不会重新生成这些属性了，包括： 1，属性名相同，类型相同，有相同的getter/setter方法； --&gt; &lt;property name="rootClass" value="com._520it.mybatis.domain.BaseDomain"/&gt; &lt;!-- 设置是否在getter方法中，对String类型字段调用trim()方法 --&gt; &lt;property name="trimStrings" value="true"/&gt; &lt;/javaModelGenerator&gt; &lt;!-- 生成SQL map的XML文件生成器， 注意，在Mybatis3之后，我们可以使用mapper.xml文件+Mapper接口（或者不用mapper接口）， 或者只使用Mapper接口+Annotation，所以，如果 javaClientGenerator配置中配置了需要生成XML的话，这个元素就必须配置 targetPackage/targetProject:同javaModelGenerator --&gt; &lt;sqlMapGenerator targetPackage="com._520it.mybatis.mapper" targetProject="src/main/resources"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;/sqlMapGenerator&gt; &lt;!-- 对于mybatis来说，即生成Mapper接口，注意，如果没有配置该元素，那么默认不会生成Mapper接口 targetPackage/targetProject:同javaModelGenerator type：选择怎么生成mapper接口（在MyBatis3/MyBatis3Simple下）： 1，ANNOTATEDMAPPER：会生成使用Mapper接口+Annotation的方式创建（SQL生成在annotation中），不会生成对应的XML； 2，MIXEDMAPPER：使用混合配置，会生成Mapper接口，并适当添加合适的Annotation，但是XML会生成在XML中； 3，XMLMAPPER：会生成Mapper接口，接口完全依赖XML； 注意，如果context是MyBatis3Simple：只支持ANNOTATEDMAPPER和XMLMAPPER --&gt; &lt;javaClientGenerator targetPackage="com._520it.mybatis.mapper" type="ANNOTATEDMAPPER" targetProject="src/main/java"&gt; &lt;!-- 在targetPackage的基础上，根据数据库的schema再生成一层package，最终生成的类放在这个package下，默认为false --&gt; &lt;property name="enableSubPackages" value="true"/&gt; &lt;!-- 可以为所有生成的接口添加一个父接口，但是MBG只负责生成，不负责检查 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;/javaClientGenerator&gt; &lt;!-- 选择一个table来生成相关文件，可以有一个或多个table，必须要有table元素 选择的table会生成一下文件： 1，SQL map文件 2，生成一个主键类； 3，除了BLOB和主键的其他字段的类； 4，包含BLOB的类； 5，一个用户生成动态查询的条件类（selectByExample, deleteByExample），可选； 6，Mapper接口（可选） tableName（必要）：要生成对象的表名； 注意：大小写敏感问题。正常情况下，MBG会自动的去识别数据库标识符的大小写敏感度，在一般情况下，MBG会 根据设置的schema，catalog或tablename去查询数据表，按照下面的流程： 1，如果schema，catalog或tablename中有空格，那么设置的是什么格式，就精确的使用指定的大小写格式去查询； 2，否则，如果数据库的标识符使用大写的，那么MBG自动把表名变成大写再查找； 3，否则，如果数据库的标识符使用小写的，那么MBG自动把表名变成小写再查找； 4，否则，使用指定的大小写格式查询； 另外的，如果在创建表的时候，使用的""把数据库对象规定大小写，就算数据库标识符是使用的大写，在这种情况下也会使用给定的大小写来创建表名； 这个时候，请设置delimitIdentifiers="true"即可保留大小写格式； 可选： 1，schema：数据库的schema； 2，catalog：数据库的catalog； 3，alias：为数据表设置的别名，如果设置了alias，那么生成的所有的SELECT SQL语句中，列名会变成：alias_actualColumnName 4，domainObjectName：生成的domain类的名字，如果不设置，直接使用表名作为domain类的名字；可以设置为somepck.domainName，那么会自动把domainName类再放到somepck包里面； 5，enableInsert（默认true）：指定是否生成insert语句； 6，enableSelectByPrimaryKey（默认true）：指定是否生成按照主键查询对象的语句（就是getById或get）； 7，enableSelectByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询语句； 8，enableUpdateByPrimaryKey（默认true）：指定是否生成按照主键修改对象的语句（即update)； 9，enableDeleteByPrimaryKey（默认true）：指定是否生成按照主键删除对象的语句（即delete）； 10，enableDeleteByExample（默认true）：MyBatis3Simple为false，指定是否生成动态删除语句； 11，enableCountByExample（默认true）：MyBatis3Simple为false，指定是否生成动态查询总条数语句（用于分页的总条数查询）； 12，enableUpdateByExample（默认true）：MyBatis3Simple为false，指定是否生成动态修改语句（只修改对象中不为空的属性）； 13，modelType：参考context元素的defaultModelType，相当于覆盖； 14，delimitIdentifiers：参考tableName的解释，注意，默认的delimitIdentifiers是双引号，如果类似MYSQL这样的数据库，使用的是`（反引号，那么还需要设置context的beginningDelimiter和endingDelimiter属性） 15，delimitAllColumns：设置是否所有生成的SQL中的列名都使用标识符引起来。默认为false，delimitIdentifiers参考context的属性 注意，table里面很多参数都是对javaModelGenerator，context等元素的默认属性的一个复写； --&gt; &lt;table tableName="userinfo" &gt; &lt;!-- 参考 javaModelGenerator 的 constructorBased属性--&gt; &lt;property name="constructorBased" value="false"/&gt; &lt;!-- 默认为false，如果设置为true，在生成的SQL中，table名字不会加上catalog或schema； --&gt; &lt;property name="ignoreQualifiersAtRuntime" value="false"/&gt; &lt;!-- 参考 javaModelGenerator 的 immutable 属性 --&gt; &lt;property name="immutable" value="false"/&gt; &lt;!-- 指定是否只生成domain类，如果设置为true，只生成domain类，如果还配置了sqlMapGenerator，那么在mapper XML文件中，只生成resultMap元素 --&gt; &lt;property name="modelOnly" value="false"/&gt; &lt;!-- 参考 javaModelGenerator 的 rootClass 属性 &lt;property name="rootClass" value=""/&gt; --&gt; &lt;!-- 参考javaClientGenerator 的 rootInterface 属性 &lt;property name="rootInterface" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeCatalog，那么在生成的SQL中，使用该指定的catalog，而不是table元素上的catalog &lt;property name="runtimeCatalog" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeSchema，那么在生成的SQL中，使用该指定的schema，而不是table元素上的schema &lt;property name="runtimeSchema" value=""/&gt; --&gt; &lt;!-- 如果设置了runtimeTableName，那么在生成的SQL中，使用该指定的tablename，而不是table元素上的tablename &lt;property name="runtimeTableName" value=""/&gt; --&gt; &lt;!-- 注意，该属性只针对MyBatis3Simple有用； 如果选择的runtime是MyBatis3Simple，那么会生成一个SelectAll方法，如果指定了selectAllOrderByClause，那么会在该SQL中添加指定的这个order条件； --&gt; &lt;property name="selectAllOrderByClause" value="age desc,username asc"/&gt; &lt;!-- 如果设置为true，生成的model类会直接使用column本身的名字，而不会再使用驼峰命名方法，比如BORN_DATE，生成的属性名字就是BORN_DATE,而不会是bornDate --&gt; &lt;property name="useActualColumnNames" value="false"/&gt; &lt;!-- generatedKey用于生成生成主键的方法， 如果设置了该元素，MBG会在生成的&lt;insert&gt;元素中生成一条正确的&lt;selectKey&gt;元素，该元素可选 column:主键的列名； sqlStatement：要生成的selectKey语句，有以下可选项： Cloudscape:相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2 :相当于selectKey的SQL为： VALUES IDENTITY_VAL_LOCAL() DB2_MF :相当于selectKey的SQL为：SELECT IDENTITY_VAL_LOCAL() FROM SYSIBM.SYSDUMMY1 Derby :相当于selectKey的SQL为：VALUES IDENTITY_VAL_LOCAL() HSQLDB :相当于selectKey的SQL为：CALL IDENTITY() Informix :相当于selectKey的SQL为：select dbinfo('sqlca.sqlerrd1') from systables where tabid=1 MySql :相当于selectKey的SQL为：SELECT LAST_INSERT_ID() SqlServer :相当于selectKey的SQL为：SELECT SCOPE_IDENTITY() SYBASE :相当于selectKey的SQL为：SELECT @@IDENTITY JDBC :相当于在生成的insert元素上添加useGeneratedKeys="true"和keyProperty属性 &lt;generatedKey column="" sqlStatement=""/&gt; --&gt; &lt;!-- 该元素会在根据表中列名计算对象属性名之前先重命名列名，非常适合用于表中的列都有公用的前缀字符串的时候， 比如列名为：CUST_ID,CUST_NAME,CUST_EMAIL,CUST_ADDRESS等； 那么就可以设置searchString为"^CUST_"，并使用空白替换，那么生成的Customer对象中的属性名称就不是 custId,custName等，而是先被替换为ID,NAME,EMAIL,然后变成属性：id，name，email； 注意，MBG是使用java.util.regex.Matcher.replaceAll来替换searchString和replaceString的， 如果使用了columnOverride元素，该属性无效； &lt;columnRenamingRule searchString="" replaceString=""/&gt; --&gt; &lt;!-- 用来修改表中某个列的属性，MBG会使用修改后的列来生成domain的属性； column:要重新设置的列名； 注意，一个table元素中可以有多个columnOverride元素哈~ --&gt; &lt;columnOverride column="username"&gt; &lt;!-- 使用property属性来指定列要生成的属性名称 --&gt; &lt;property name="property" value="userName"/&gt; &lt;!-- javaType用于指定生成的domain的属性类型，使用类型的全限定名 &lt;property name="javaType" value=""/&gt; --&gt; &lt;!-- jdbcType用于指定该列的JDBC类型 &lt;property name="jdbcType" value=""/&gt; --&gt; &lt;!-- typeHandler 用于指定该列使用到的TypeHandler，如果要指定，配置类型处理器的全限定名 注意，mybatis中，不会生成到mybatis-config.xml中的typeHandler 只会生成类似：where id = #&#123;id,jdbcType=BIGINT,typeHandler=com._520it.mybatis.MyTypeHandler&#125;的参数描述 &lt;property name="jdbcType" value=""/&gt; --&gt; &lt;!-- 参考table元素的delimitAllColumns配置，默认为false &lt;property name="delimitedColumnName" value=""/&gt; --&gt; &lt;/columnOverride&gt; &lt;!-- ignoreColumn设置一个MGB忽略的列，如果设置了改列，那么在生成的domain中，生成的SQL中，都不会有该列出现 column:指定要忽略的列的名字； delimitedColumnName：参考table元素的delimitAllColumns配置，默认为false 注意，一个table元素中可以有多个ignoreColumn元素 &lt;ignoreColumn column="deptId" delimitedColumnName=""/&gt; --&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt;]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>框架</tag>
        <tag>Mybatis Generator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 配置文件详解]]></title>
    <url>%2F2018%2F04%2F04%2FNginx%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言Nginx（发音同engine x）是一个异步框架的 Web服务器，也可以用作反向代理，负载平衡器 和 HTTP缓存。Nginx是一款面向性能设计的HTTP服务器，相较于Apache、lighttpd具有占有内存少，稳定性高等优势。与旧版本（&lt;=2.2）的Apache不同，Nginx不采用每客户机一线程的设计模型，而是充分使用异步逻辑从而削减了上下文调度开销，所以并发服务能力更强。整体采用模块化设计，有丰富的模块库和第三方模块库，配置灵活。 因此，在此记录下Nginx的配置详解，以作备用。 Nginx 配置文件详解nginx官方文档 如果是使用apt-get安装的Nginx，则主配置文件位于 /etc/nginx下，通过ls指令可以看到： 12345678nginx.conf 这个是nginx的主配置文件,里面包含了当前目录的所有配置文件,只不过有的是注释状态,需要的时候自行开启(后面几个常用的)conf.d 这是一个目录,里面可以写我们自己自定义的配置文件,文件结尾一定是.conf才可以生效(当然也可以通过修改nginx.conf来取消这个限制)sites-enabled 这里面的配置文件其实就是sites-available里面的配置文件的软连接,但是由于nginx.conf默认包含的是这个文件夹, 所以我们在sites-available里面建立了新的站点之后,还要建立个软连接到sites-enabled里面才行 sites-available 这里是我们的虚拟主机的目录，我们在在这里面可以创建多个虚拟主机 nginx.conf 配置区域nginx.conf是Nginx的主配置文件，里面主要包括以下几个配置区域： main配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 event配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。 http可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 upstream配置HTTP负载均衡器分配流量到几个应用程序服务器。 server配置虚拟主机的相关参数，一个http中可以有多个server。 location配置请求的路由，以及允许根据用户请求的URI来匹配指定的各location以进行访问配置；匹配到时，将被location块中的配置所处理。 nginx.conf 文件内容nginx.conf文件的内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586user www-data;worker_processes auto;pid /run/nginx.pid;include /etc/nginx/modules-enabled/*.conf;events &#123; worker_connections 768; # multi_accept on;&#125;http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable &quot;msie6&quot;; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125;#mail &#123;# # See sample authentication script at:# # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript# # # auth_http localhost/auth.php;# # pop3_capabilities &quot;TOP&quot; &quot;USER&quot;;# # imap_capabilities &quot;IMAP4rev1&quot; &quot;UIDPLUS&quot;;# # server &#123;# listen localhost:110;# protocol pop3;# proxy on;# &#125;# # server &#123;# listen localhost:143;# protocol imap;# proxy on;# &#125;#&#125; 配置详解核心功能配置nginx核心功能配置主要是main和events的顶层全局配置，都是配置nginx核心模块（ngx_core_module），管理服务器级别的行为。下面介绍的是大部分常用的配置选项，更多配置请参考官方文档 main基本配置 error_log file [level]; 注：该项可以配置在任何配置区域 配置错误日志文件的路径和日志级别。日志级别有debug, info, notice, warn, error, crit, alert和emerg几种。调试时可以使用debug级别，但要求在编译时必须使用–with-debug启用debug功能，默认通常为error级别。 user username [groupname] 默认nobody 定义Nginx运行的用户和用户组 pid /run/nginx.pid; 默认nginx.pid 指定nginx的进程文件 worker_rlimit_nofile number; 无默认 指定一个worker进程所能够打开的句柄数。 daemon on | off; 默认on nginx是否以守护进程运行，是否让nignx运行于后台。 master_process on | off; 默认on 是否以master/worker模式运行nginx，默认为on。 性能优化 worker_processes number | auto; 默认1 nginx进程数，建议设置为等于CPU总核心数。而且，nginx为了更好的利用多核特性，具有cpu绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来cache的失效。 worker_cpu_affinity cpumask …; 无默认，不绑定 将工作进程绑定到特定的CPU上，减少CPU在进程之间切换的开销。用二进制bit位表示进程绑定在哪个CPU内核。如：worker_cpu_affinity 0001 0010 0100 1000。 worker_priority number; 默认0 工作进程调度优先级，-20到19之间的值，值越小越优先调用。 timer_resolution interval; 无默认 每次内核事件调用返回时，都会使用gettimeday（）来更新nginx缓存时钟；timer_resolution用于定义每隔多久才会由gettimeday（）更新一次缓存时钟；x86-64系统上，gettimeday()代价已经很小，可以忽略此配置。 ssl_engine device; 无默认 在存在ssl硬件加速器的服务器上，指定所使用的ssl硬件加速设备。由于https链接所消耗的资源比http大得多，可能要多消耗5、6倍，最好有专门处理ssl的硬件设备。 events worker_commections number; 默认512 每个worker能够并发响应的最大请求数。系统每处理一个请求就要消耗一个套接字文件，如果为代理服务器的话，worker_rlimit_nofile=worker_commections*2。 use method; 无默认，自动选择 指定使用哪种模型，建议让nginx自动选择。 注意： 与apache相似，nginx针对不同的操作系统，有不同的事件模型。 标准事件模型 Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll。 高效事件模型 Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 Epoll：使用于Linux内核2.6版本及以后的系统。 /dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 accept_mutex on | off; 默认off 是否打开nginx的accept锁；此锁能够让多个worker进行轮流地、序列化地与新的客户端建立连接；而通常当一个worker进程的负载达到其上限的7/8，master就尽可能不将请求调度至worker。 accept_mutex_delay time; 默认500ms 使用accept锁以后，只有一个worker能取得锁，一个worker进程为取得accept锁的等待时长，即用户建立等待的时间，如果某worker进程在某次试图取得锁时失败了，至少要等待#ms才能在一次请求锁。 multi_accept on | off; 默认off 是否允许一次性地响应多个用户请求。 HTTP核心配置http功能核心配置主要是http块、server块和location块的配置，包括HTTP核心模块（ngx_http_core_module）和一些扩展模块（如ngx_stream_ssl_module），提供管理WEB服务器级别的行为。 必须使用虚拟机来配置站点，每个虚拟主机使用一个server{}段来配置，非虚拟主机的配置和公共选项，需要定义在server之外，http之内。 下面包含是大部分常用的配置选项，更多配置请参考官方文档 main http { … } 提供HTTP服务器配置上下文 http server { … } HTTP服务器的核心配置，定义一个虚拟主机：nginx支持使用基于主机名或IP的虚拟主机。 server listen address[:port] | listen prot | listen unix:socket 默认 listen :80 | :8000 配置虚拟主机监听的IP地址和端口，默认监听本机IP地址和80或8000端口。如果只设置了IP没设端口，默认使用80端口。如果只设置了端口，没设置IP默认使用本机IP。 后面可以指定一些参数： default_server:定义此server为http中默认的server；如果所有的server中任何一个listen使用此参数，那么第一个server即为默认server； rcvbuf=SIZE：接收缓存大小； sndbuf=SIZE: 发送缓存大小； ssl：https server：必须以ssl连接； server_name name …; 配置虚拟主机的域名，可以指定多个，用空格分隔。默认为空。 名称可以使用通配符和正则表达式（通常以~开头）：当nginx收到一个请求时，会取出其首部的server的值，而后跟众server_name进行比较：比较方式 先做精确匹配，如www.example.com 左侧通配符匹配，如*example.com 右侧通配符匹配，如www.* 正则表达式匹配 server_name_hash_bucket_size size; 默认32|64|128 为了实现快速主机查找，nginx使用hash表来保存主机名。默认值取决于处理器缓存线的大小。 location alias path; 无默认 指定路径别名，只能用于location中，从最后一个/开始匹配。 如location /i/ { alias /example/; } 请求”/i/a.gif”, 实际文件”/example/a.gif” limit_except method … { … } 指定范围之外的其他方法的访问控制。 方法有：GET, HEAD, POST, PUT, DELETE, MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, or PATCH. 如只允许GET访问： limit_except GET { allow 192.168.1.0/32; deny all; } server, location location [ = | ~ | ~* | ^~ ] uri { … } | location @name { … } 无默认 允许根据用户请求的URI来匹配指定的各location以进行访问配置；匹配到时，将被location块中的配置所处理。 =：精确匹配； ~：正则表达式模式匹配，匹配时区分字符大小写； ~*：正则表达式模式匹配，匹配时忽略字符大小写； ^~：只需要前半部分与uri匹配即可，不检查正则表达式； 匹配优先级： 字符字面量最精确匹配、正则表达式检索（由多个时，由第一个匹配到的所处理），按字符字面量。 try_files file … uri | try_files file … =code; 无默认 自左向右尝试读取有path所指定路径，在第一找到即停止并返回，如果所有path均不存在，则返回最后一个uri或者code. 如try_files $uri $uri/index.html $uri.html =404; http, server client_header_timeout time; 默认60s 读取http请求首部的超时时长。如果客户端在此时间内未传输整个头，则会向客户端返回408（请求超时）错误。 ignore_invalid_headers on | off; 默认on 是否忽略不合法的http首部，默认为on，off意味着请求首部中出现不合规的首部将拒绝响应。 http, server, location root path; 默认html 设置web资源路径，用于指定请求的根文档目录，从根开始匹配。 index file …; 默认index，html 定义默认页面，可以跟多个值。自左向右匹配。 error_page code … [=[response]] uri; 无默认 当对于某个请求发回错误时，如果匹配上了error_page指令中设定的code，则重定向至新的URI中，错误重定向。 如 error_page 500 502 503 504 /50x.html; 也可以改变返回码。 如error_page 404 =200 /404.html; keepalive_timeout timeout [header_timeout]; 默认75s 保持连接的超时时长，默认为75s。降低每个连接的alive时间可在一定程度上提高可响应连接数量，所以一般可适当降低此值。 keepalive_requests number; 默认100 在一次长连接上允许承载的最大请求数。 keepalive_disable none | browser …; 默认msie6（ie6无法长连接） 对指定的浏览器禁止使用长连接。 tcp_nodelay on | off; 默认on 对keepalive连接是否使用tcp_nodelay选项 启动配置，会在数据包达到一定大小后再发送数据。这样会减少网络通信次数，降低阻塞概率，但也会影响响应及时性。比较适合于文件下载这类的大数据通信场景。 client_body_timeout time; 默认60s 读取http请求包体的超时时间。 send_timeout time; 默认60s 发送响应的超时时长。超时后连接将关闭。 client_max_body_size size; 默认1m http请求包体的最大值，常用于限定客户端所能够请求的最大包体，根据请求首部中的Content-Length来检查，以避免无用的传输。 limit_rate rate; 默认0 限制客户端每秒传输的字节数，默认为0，表示没有限制。 limit_rate_after size; 默认0 nginx向客户端发送响应报文时，如果时长超过了此处指定的时长，则后续的发送过程开始限速（下载站点常用）。 配合上面的limit_rate使用。 log_not_found on | off; 默认on 用户访问的文件不存在时，是否将其记录到错误日志中。 resolver address … [valid=time] [ipv6=on|off]; 无默认 指定nginx使用的dns服务器地址。 valid = 30s，缓存时间设置。在1.1.9版之前，不能调整缓存时间，而nginx总是缓存大概5分钟的时间。 resolver_timeout time; 默认30s 指定DNS解析超时时长。 server_tokens on | off | string; 默认on 是否在错误页面中显示和”响应头字段中发出nginx的版本号。从版本1.9.13开始，可以使用带有变量的字符串显式设置。空字符串禁用。 sendfile on | off; 默认off 是否启用sendfile内核复制模式功能。 作为静态服务器可以提高最大的IO访问速度。传统的文件读写采用read和write方式，流程为：硬盘 &gt;&gt; kernel buffer &gt;&gt; user buffer&gt;&gt; kernel socket buffer &gt;&gt;协议栈，采用sendfile文件读写的流程为：硬盘 &gt;&gt; kernel buffer (快速拷贝到kernel socket buffer) &gt;&gt;协议栈，很明显sendfile这个系统调用减少了内核到用户模式之间的切换和数据拷贝次数，直接从内核缓存的数据拷贝到协议栈，提高了很大的效率。 aio on | off | threads[=pool]; 默认off 是否启用异步文件IO功能。 Linux从内核版本2.6.22开始支持，有必要启用directio，否则读取将阻塞。 directio只能用于读取在512字节边界（或XFS为4K）上对齐的块。文件结束未对齐将在阻塞模式下读取。 当在Linux上同时启用aio和sendfile功能时，aio用于大于或等于directio指令中指定大小的文件，而小于或禁用directio时则用sendfile。 location /video/ { sendfile on; aio on; directio 8m; } open_file_cache off | open_file_cache max=N [inactive=time]; 默认off 是否打开文件缓存功能。 max：用于缓存条目的最大值，允许打开的缓存条目最大数，当满两类以后将根据LRU（最小最少连接数）算法进行置换 inactive：某缓存条目在指定时长内没有被访问过时，将自动被删除，即缓存有效期，通常默认为60s。 缓存的信息包括： 文件句柄、文件大小和上次修改时间； 已经打开的目录结构； 没有找到或没有访问权限的信息等。 open_file_cache_errors on | off; 默认off 是否缓存文件找不到或没有权限访问等相关信息。 open_file_cache_valid time; 默认60s 多长时间检查一次缓存中的条目是否超出非活动时长。 open_file_cache_min_uses number; 默认1 在open_file_cache inactive指定的时长内被访问超过此处指定的次数时，才不会被删除（删除低命中率的缓存）。 gzip on | off; 默认off 开启内容压缩，可以有效降低客户端的访问流量和网络带宽 gzip_min_length length; 默认20k 内容超过最少长度后才开启压缩，因为太短的内容压缩效果不佳，且压缩过程还会浪费系统资源。这个压缩长度会作为http响应头Content-Length字段返回给客户端。 gzip_comp_level 1~9; 默认1 压缩级别，默认值为1。范围为1～9级，压缩级别越高压缩率越高，但对系统性能要求越高。 gzip_types mime-type …; 默认text/html 压缩内容类型，默认为text/html;。只压缩html文本，一般我们都会压缩js、css、json之类的，可以把这些常见的文本数据都配上。如：text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript; 配置变量nginx配置文件支持使用变量，可以使用内置变量或自定义变量。用户自定义变量语法：set var_name value；http核心模块的内置变量 主要配置如下: 123456789101112131415161718192021222324252627282930313233$uri:当前请求的uri，不带参数 $request_uri：请求的uri，带完整参数 $host：http请求报文中host首部；如果请求中没有host首部，则以处理此请求的主机的主机名代替 $hostname：nginx服务运行所在主机的主机名 $remote_addr：客户端IP $remote_port: 客户端port $remote_user：使用用户认证时客户端用户输入的用户名 $request_filename：用户请求中的URI经过本地root或alias转换后映射的本地的文件路径 $request_method：请求方法 $server_addr：服务器地址 $server_name: 服务器名称 $server_port：服务器端口 $server_protocol：服务器向客户端发送响应时的协议，如http/1.1，http/1.0 $scheme:在请求中使用的scheme 映射协议本身的协议 $http_HEADER:匹配请求报文中指定的HEADER，$http_host匹配请求报文中的host首部 $sent_http_HEADER:匹配响应报文中指定的HERDER，例如$http_content_type匹配相应报文中的content-type首部 $document_root：当前请求映射到的root配置 反向代理反向代理是nginx服务器最常用的功能之一： 1. 正向代理 正向代理是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端才能使用正向代理。 正向代理允许客户端通过它访问任意网站并且隐藏客户端自身。 典型用途：为在防火墙内的局域网客户端提供访问Internet的途径，一个是提高安全性，一个VPN翻墙；可以利用缓冲特性减少网络使用率。 2. 反向代理 反向代理是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。 典型用途：将防火墙后面的服务器提供给Internet用户访问，提高服务器的安全性。反向代理还可以为后端的多台服务器提供负载平衡，或为后端较慢的服务器提供缓冲服务。 配置选项nginx的反向代理基于ngx_http_proxy_module，该模块有许多功能。 proxy_connect_timeout：nginx将一个请求发送至upstream server之前等待的最大时长； proxy_cookie_domain：将upstream server通过Set-Cookie首部设定的domain属性修改为指定的值，其值可以为一个字符串、正则表达式的模式或一个引用的变量； proxy_cookie_path: 将upstream server通过Set-Cookie首部设定的path属性修改为指定的值，其值可以为一个字符串、正则表达式的模式或一个引用的变量； proxy_hide_header：设定发送给客户端的报文中需要隐藏的首部； proxy_pass：指定将请求代理至upstream server的URL路径； proxy_set_header：将发送至upsream server的报文的某首部进行重写； proxy_redirect：重写location并刷新从upstream server收到的报文的首部； proxy_send_timeout：在连接断开之前两次发送至upstream server的写操作的最大间隔时长； proxy_read_timeout：在连接断开之前两次从接收upstream server接收读操作的最大间隔时长； 此外还有如缓存配置等等。 配置proxy_pass反向代理proxy_pass配置可分三种： location的uri将被替换为上游服务器上的newuri 12345location /uri &#123; proxy_pass http://ip:port/newuri; &#125; 如果location的URI是通过模式匹配定义的，其URI将直接被传递至上游服务器，而不能为其指定转换的另一个URI。 123location / &#123; proxy_pass http://192.168.1.1:8080;&#125; 也就是说不能代理后面不能加新的URI，加了会报错 如果在loation中使用的URL重定向，那么nginx将使用重定向后的URI处理请求，而不再考虑上游服务器上定义的URI。 1234567location / &#123; rewrite http://192.168.1.1/rewrite; proxy_pass http://192.168.1.1/proxy; &#125; 配置proxy_set_header，客户端信息记录到日志如果请求经过nginx反向代理服务器，后端web服务器无法直接获取到客户端真实的IP地址，因为$remote_addr获取到的是反向代理IP地址 可以通过proxy_set_header配置反向代理服务器在转发请求的http头信息中增加”X-Forwarded-For”行信息，该信息中记录客户端IP地址。 1234567location / &#123; proxy_pass http://192.168.1.1/proxy; #本机代理到&quot;http://192.168.1.1/proxy proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #$remote_addr; #代理转发的请求头部增加&quot;X-Forwarded-For&quot;客户端地址 &#125; 负载均衡和健康检查nginx负载均衡是ngx_http_upstream_module的功能 需要在配置文件http块上下文中定义upstream块，指定一组负载均衡的后端服务器，然后在上面说的proxy_pass中引用，就可以在反向代理时实现负载均衡 配置选项 server address [parameters]; paramerters： weight：负载均衡策略权重，默认为1； max_fails：允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误； fail_timeout：在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用，进行对后端服务器的健康状态检查； backup：当所有后端服务器都宕机时，可以指定代理服务器自身作为备份，对外提供维护提示页面； down：永久不可用。 upstream块里可以用多个server选项配置多个后端服务器，同时还可配置对后端服务器的健康状态检查，可以在server后面加上max_fails（proxy_next_upstream指定检查策略，默认为返回超时为失败）和fail_timeout参数实现；也可以用health_check选项来实现，health_check可以指定的参数较多，不过需要定义在location上下文中。 另外，可以指定代理服务器自身作为备份server，当所有后端服务器都宕机时，对外提供维护提示页面。 还可以指定负载均衡策略：主要有round_robin（加权轮询，默认）、hash、ip_hash、least_conn（最少连接）和least_time（最少响应时间，商业版本），策略定义在upstream上下文即可; 配置操作先在配置一个名为web的upstream块，里面包含三个server：server1、server2和代理服务器自身，配置对后端服务器的健康状态检查、负载均衡策略；然后在location中的proxy_pass中引用该web组，配置如下 1234567891011121314151617181920212223242526272829303132333435363738upstream webserver &#123; #定义名为web的负载均衡组，在下面proxy_pass引用 #ip_hash; #ip_hash负载均衡策略，注意，当下面定义代理服务器为backup时，当后端服务器重新上线时，不能进行正常转发 least_conn; #最少连接负载均衡策略 #least_time last_byte; #最少响应时间策略,商业版本 server 192.168.1.1 weight=2 max_fails=2 fail_timeout=2; #server1 权重2 两次检测失败，不向其转发 检查超时两秒为失败 server 192.168.1.2 weight=1 max_fails=2 fail_timeout=2; #server2 server 127.0.0.1:8080 weight=1 backup; #指定代理服务器自身作为备份server，当所有后端服务器都宕机时，对外提供维护提示页面 &#125; server &#123; listen 80; server_name localhost; #charset utf-8; #access_log logs/access.log error; location / &#123; proxy_pass http://web; #引用上面定义的upstream负载均衡组 &#125; &#125; 缓存Nginx常用的缓存可以分为四类： pxory_cache：代理缓存，作为代理服务器时，缓存后端服务器响应内容等； open_log_cache：日志缓存； open_file_cache：文件缓存，作为WEB服务器时需要响应文件给客户端。 fastcgi_cache：后端动态响应内容缓存，可能影响响应内容更新。 缓存数据分为两部分（键：数据）： 存储键和缓存对象元数据，存放在共享内存中; 存储缓存数据，存放在磁盘空间中； 代理缓存配置选项这里只介绍代理缓存pxory_cache，这也是ngx_http_proxy_module模块提供的功能，这里配置选项较多，下面主要介绍有几个基本的选项：proxy_cache_path、proxy_cache和proxy_cache_valid。 proxy_cache_pathproxy_cache_path定义一个完整的缓存空间，指定缓存数据的磁盘路径、键（元数据）存放的内存空间以及一些其他参数，如缓存删除策略。注意，该选项只能定义在http块上下文中。 123456789101112如:proxy_cache_path /etc/nginx/cache levels=1:2 keys_zone=one:10m max_size=1G inactive=10; 缓存数据存储在/etc/nginx/cache目录中； levels:配置在该目录下再分两层目录，一层1个随机字符作为名称，二层2个随机字符作为名称，levels最多三层，每层最多两个字符，这是为了加快访问文件的速度； 最后使用代理url的哈希值作为关键字与文件名，一个缓存数据如下：/etc/nginx/cache/c/29/b7f54b2df772f4809d65029c； keys_zone:指定键（元数据）存放的内存空间，指定名称为one，这个名称后面proxy_cache需要引用；而10m就是内存空间的大小； max_size:指定最大缓存数据磁盘空间的大小； inactive:在inactive指定的时间内，未被访问的缓存数据将从缓存中删除。 proxy_cacheproxy_cache用来引用上面proxy_cache_path定义的缓存空间，现时打开缓存功能，如下： 1proxy_cache one； #引用上面定义上的缓存空间，同一缓存空间可以在几个地方使用 proxy_cache_validproxy_cache_valid设置不同响应代码的缓存时间。123proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; 配置代理缓存先配置pxory_cache_path，再配置pxory_cache引用、打开缓存空间，接着配置两个proxy_cache_valid； 12345678910111213141516171819202122proxy_cache_path /etc/nginx/cache levels=1:2 keys_zone=one:10m max_size=1G inactive=10m; server &#123; listen 80; server_name localhost; #charset utf-8; #access_log logs/access.log error; add_header X-Cache &quot;$upstream_cache_status form $server_addr&quot;; #给请求响应增加一个头部信息，表示从服务器上返回的cache状态怎么样（有没有命中） location / &#123; proxy_pass http://web; #引用上面定义的upstream负载均衡组 proxy_cache one; #引用上面定义上的缓存空间，同一缓存空间可以在几个地方使用 proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; #对代码200和302的响应设置10分钟的缓存，对代码404的响应设置为1分钟: &#125; &#125;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat 配置文件详解]]></title>
    <url>%2F2018%2F04%2F03%2FTomcat%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前言Tomcat隶属于Apache基金会，是开源的轻量级WEB应用服务器，使用非常广泛。server.xml是Tomcat中最重要的配置文件，server.xml的每一个元素都对应了Tomcat中的一个组件；通过对xml文件中元素的配置，可以实现对Tomcat中各个组件的控制。 故搜索一些server.xml配置文件的详解，留以备用。 tomcat 自带的 server.xml 文件server.xml 位于 Tomcat 的 conf 目录下，下面是 tomcat 自带的 server.xml 文件 12345678910111213141516171819202122232425262728293031323334353637&lt;Server port="8005" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JasperListener" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="WEBapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 整体结构整体结构如下 1234567891011&lt;Server&gt; &lt;Service&gt; &lt;Connector /&gt; &lt;Connector /&gt; &lt;Engine&gt; &lt;Host&gt; &lt;Context /&gt;&lt;!-- 现在常常使用自动部署，不推荐配置Context元素，Context小节有详细说明 --&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 元素分类server.xml 文件中的元素可大致分为四类： 顶层元素: &lt;Server&gt; 和 &lt;Service&gt; 其中 Server 元素是整个配置文件的根元素， Service 元素则代表一个 Engine 元素和一组与之相连的 Connector 元素。 连接器: &lt;Connector&gt; Connector 元素代表了外部客户端发送请求到特定 Service 的接口；同时也是外部客户端从特定 Service 接收响应的接口 容器: &lt;Engine&gt;&lt;Host&gt;&lt;Context&gt; 容器的作用是处理 Connector 接收进来的请求，并产生相应的响应。 Engine 、 Host 、 Context 都是容器，但他们是父子关系： Engine 包含 Host ， Host 包含 Context 。一个 Engine 组件可以处理 Service 中所有的请求，一个 Host 组件可以处理发向特定虚拟主机的所有请求， 一个 Context 组件可以处理一个特定的 WEB 应用的所有请求。 内嵌组件: 可以内嵌到容器中的组件。其实， Server 、 Service 、 Connector 、 Engine 、 Host 和 Context 是最重要的最核心的 Tomcat 组件，其他组件都可以归为内嵌组件。 核心组件ServerServer 元素在最顶层，代表整个 Tomcat 容器，因此他必须是 server.xml 中唯一一个最外层元素。一个 Server 元素中可以有一个或多个 Service 元素。 在自带的 server.xml 文件中，最外层有一个 Server 元素， shutdown 属性表示关闭 Server 的指令； port 属性表示 Server 接收 shutdown 指令的端口，设置为 -1 可以禁掉该端口。可选属性： className ，值需要是实现了org.apache.catalina.Server接口的类名，标准实现类是org.apache.catalina.core.StandardServer类。 Server 的主要任务，就是提供一个接口让客户端能够访问到这个 Service 集合，同时维护他所包含的所有 Service 的生命周期，包括如何初始化、如何结束服务、如何找到客户端要访问的 Service 。 ServiceService 元素的作用是在 Connector 和 Engine 外面包一层，将他们组装在一起，对外提供服务。一个 Service 可以包含多个 Connector ，但是只能包含一个 Engine ；其中 Connector 的作用是接收客户端请求， Engine 的作用是处理接收进来的请求。 在自带的 server.xml 文件中， Server 中包含一个名称为 “Catalina” 的 Service 。实际上， Tomcat 可以提供多个 Service ，不同的 Service 监听不同的端口。 ConnectorConnector 元素的主要功能是接收连接的请求，创建 Request 和 Response 对象用于和请求端交换数据；然后分配线程让 Engine 来处理这个请求，并把产生的 Request 和 Response 对象传给 Engine 。 通过配置 Connector ，可以控制请求 Service 的协议和端口。 12&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt;&lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; 在自带的 server.xml 文件中， Service 包含两个 Connector ： 通过配置第一个 Connector ，客户端可以通过8080端口使用http协议访问 Tomcat ，其中， protocol 属性规定了请求的协议， port 属性规定了请求的端口号， redirectPort 属性表示当强制要求https而请求是http时，重定向至端口号为8443的 Connector ， connectionTimeout 属性表示连接的超时时间。 通过配置第二个 Connector ，客户端可以通过8009端口使用AJP协议访问Tomcat，AJP协议负责和其他的HTTP服务器（如Apache）建立连接；在把 Tomcat 与其他HTTP服务器集成时，就需要用到这个连接器。之所以用 Tomcat 和其他服务器集成，是因为 Tomcat 可以用作 Servlet/JSP 容器，但是对静态资源的处理速度较慢，不如 Apache 和 IIS 等HTTP服务器；因此常常将 Tomcat 与 Apache 等集成，前者作为 Servlet 容器，后者处理静态资源，而AJP协议便负责 Tomcat 和 Apache 的连接， Tomcat 和 Apache 等集成的原理如下图： ; EngineEngine 元素在 Service 中有且只有一个； Engine 是 Service 组件中的请求处理组件。 Engine 组件从一个或多个 Connector 中接收请求并处理，并将完成的响应返回给 Connector ，最终传递给客户端。 &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; 上面的配置语句，其中name属性用于日志和错误信息，在整个 Service 中应该唯一。 defaultHost 属性指定了默认的 host 名称，当发生本机的请求指定的 host 名称不存在时，一律使用 defaultHost 指定的 host 进行处理；因此， defaultHost 的值必须与 Engine 的一个 Host 组件的name属性值匹配。 HostEngine 和 HostHost 是 Engine 的子容器， Engine 组件中可以内嵌一个或多个 Host 组件，每个 Host 组件代表 Engine 中的一个虚拟主机。 Host 组件至少有一个，且其中一个的 name 必须与 Engine 组件的 defaultHost 属性相匹配。 Host 的作用Host 虚拟主机的作用，是运行多个WEB应用（一个 Context 代表一个 WEB 应用），并负责安装、展开和结束每个 WEB 应用。 Host 组件代表的虚拟主机，对应了服务器中一个网络名实体（如”www.soloist.top”,或IP地址”114.114.114.114”）；为了使用户可以通过网络名连接 Tomcat 服务器，这个名字应该在 DNS 服务器上注册。 客户端通常使用主机名来标识他们希望连接的主机；该主机名也会包含在HTTP请求头中。 Tomcat 从 HTTP 头中提取出主机名，寻找名称匹配的主机。如果没有主机匹配，请求将发送至默认主机（localhost）。因此默认主机不需要是在 DNS 服务器中注册的网络名，因为任何与所有 Host 名不匹配的请求，都会路由至默认主机。 Host 的配置1&lt;Host name="localhost" appBase="WEBapps" unpackWARs="true" autoDeploy="true"&gt; 上面的配置项中，name属性指定虚拟主机的主机名，一个 Engine 中有且仅有一个 Host 组件的 name 属性与 Engine 组件的 defaultHost 属性相匹配；一般情况下，主机名需要是在 DNS 服务器中注册的网络名，但是 Engine 指定的 defaultHost 不需要。 unpackWARs 属性指定了是否将代表 WEB 应用的 WAR 文件解压；如果为 true ，通过解压后的文件结构运行该 WEB 应用，如果为 false ，直接使用 WAR 文件运行 WEB 应用。 Host 中的 autoDeploy 属性与配置中未出现的 xmlBase 和 deployOnStartup 属性，都与 WEB 应用中的自动部署有关，将在 Context 中介绍。 ContextContext 的作用Context 元素代表在特定虚拟主机上运行的一个 WEB 应用。在后文中，提到的 Context 、 应用或 WEB 应用，都指代的是 WEB 应用。每个 WEB 应用基于 WAR 文件，或 WAR 文件解压后对应的目录（称为应用目录）。 Context 是 Host 的子容器，每个 Host 中可以定义任意多的 Context 元素。 在自带的 server.xml 文件中，我们可以发现并没有 Context 元素的配置，因为 Tomcat 开启了自动部署， WEB 应用没有在配置文件中静态部署，而是由 Tomcat 通过特定的规则自动部署。 WEB 应用自动部署Host 的配置 要开启自动部署，需要配置所在的虚拟主机；配置的方式就是前面提到的 deployOnStartup 和 autoDeploy 属性。如果 deployOnStartup 和 autoDeploy 设置为 true ，则 Tomcat 启动自动部署；当检测到新的 WEB 应用或 WEB 应用的更新时，会触发应用的部署（或重新部署）。二者的主要区别在于， deployOnStartup 为 true 时， Tomcat 在启动时检查 WEB 应用，且检测到所有的 WEB 应用视作新应用； autoDeploy 为 true 时， Tomcat 在运行时定期检查新的 WEB 应用或 WEB 应用的更新。除此之外，二者的处理相似。 通过配置 deployOnStartup 和 autoDeploy 可以开启虚拟主机自动部署 WEB 应用；实际上，自动部署依赖于检查是否有新的或更改过的 WEB 应用。而 Host 元素的 appBase 和 xmlBase 设置了检查 WEB 应用更新的目录。 其中， appBase 属性指定 WEB 应用所在的目录，默认值是 WEBapps ，这是一个相对路径，代表 Tomcat 根目录下的 WEBapps 文件夹。 xmlBase 属性指定 WEB 应用的 xml 配置文件所在的目录，默认值是 conf//，例如在自带文件中，主机 localhost 的 xmlBase 默认值为 Tomcat 根目录下 conf/Catalina/localhost。 检查 WEB 应用更新 一个WEB应用可能包含以下文件：xml配置文件，WAR包，以及一个应用目录（该目录包含WEB应用的文件结构）；其中xml配置文件位于xmlBase指定的目录，WAR包和应用目录位于appBase指定的目录。 Tomcat 按如下的顺序进行扫描，检查应用更新。 扫描虚拟主机指定的xmlBase下的xml配置文件。 扫描虚拟主机指定的appBase下的WAR文件。 扫描虚拟主机指定的appBase下的应用目录。 Context 元素的配置 Context 元素最重要的属性是 docBase 和 path ，此外 reloadable 属性也比较常用。 docBase 指定了该 WEB 应用使用的 WAR 包路径，或应用目录，需要注意的是，在自动部署场景下（配置文件位于xmlBase中），docBase不在appBase目录中，才需要指定；如果 docBase 指定的 WAR 包或应用目录就在 appBase 中，则不需要指定，因为 Tomcat 会自动扫描appBase中的WAR包和应用目录，指定了反而会造成问题。 path 指定了访问该 WEB 应用的上下文路径，当请求到来时， Tomcat 根据 WEB 应用的 path 属性与 URI 的匹配程度来选择 WEB 应用处理相应请求。例如， WEB 应用 app1 的 path 属性是 “/app1”， WEB 应用 app2 的 path 属性是 “/app2”，那么请求/app/index.html会交给app1来处理，而请求/app2/index.html会交给app2来处理。如果一个Context元素的path属性为””，那么这个Context是虚拟主机的默认WEB应用；当请求的url与所有的path都不匹配时，使用该默认WEB应用来处理。 需要注意的是，在自动部署场景下（配置文件位于xmlBase中），不能指定path属性，path属性由配置文件的文件名、WAR文件的文件名或应用目录的文件名称自动推导出来。如扫描WEB应用时，发现了xmlBase目录下的app1.xml，或appBase目录下的app1.WAR或app1应用目录，则该WEB应用的path属性是”app1”，如果名称是ROOT，则该WEB应用是虚拟主机默认的WEB应用，此时path属性推导为””。 reloadable属性指示Tomcat是否在运行时监控在WEB-INF/classes和WEB-INF/lib目录下的class文件的改动。如果为true，则当class文件改动时，会触发WEB应用的重新加载。在开发环境下，reloadable设置为true便于测试，但是在生产环境中设置为true会给服务器性能带来压力，因此默认值为false。 自动部署举例 最典型的自动部署，就是当我们安装完Tomcat后，WEBapps目录下有如下文件夹： 12345- docs- example- host-manager- manager- ROOT 当我们启动Tomcat后，可以使用http://localhost:8080/来访问Tomcat，其实访问的就是ROOT对应的WEB应用；我们也可以通过http://localhost:8080/docs来访问docs应用，其他同理。 server.xml中静态部署WEB应用除了自动部署，我们也可以在server，xml中通过元素静态部署WEB应用。静态部署和动态部署是可以共存的，在实际应用中，并不推荐使用静态部署，因为server.xml是不可动态加载的资源，服务器一旦启动了以后，要修改这个文件，只有重启服务器才能加载。而自动部署可以在Tomcat运行时通过定期的扫描来实现，不需要重启服务器。 server.xml中使用Context元素配置WEB应用，Context元素应该位于Host元素中 docBase：静态部署时，docBase可以在appBase目录下，也可以不在。 path：静态部署时，可以显式指定path属性，但是仍然受到了严格的限制：只有当自动部署完全关闭(deployOnStartup和autoDeploy都为false)或docBase不在appBase中时，才可以设置path属性。在本例中，docBase不在appBase中，因此path属性可以设置。 reloadable属性的用法与自动部署时相同。 核心组件的关联整体关系核心组件的整体关系，可以总结如下： Server元素在最顶层，代表整个Tomcat容器；一个Server元素中可以有一个或多个Service元素。 Service在Connector和Engine外面包了一层，把它们组装在一起，对外提供服务。一个Service可以包含多个Connector，但是只能包含一个Engine；Connector接收请求，Engine处理请求。 Engine、Host和Context都是容器，且 Engine包含Host，Host包含Context。每个Host组件代表Engine中的一个虚拟主机；每个Context组件代表在特定Host上运行的一个WEB应用。 如何确定请求由谁处理？根据协议和端口号选定Service和EngineService中的Connector组件可以接收特定端口的请求。因此，当Tomcat启动时，Service组件便会监听特定端口，在上面的配置文件中，Catalina这个Service监听了基于HTTP协议的8080端口和基于AJP协议的8009端口。当请求进来时，Tomcat便可以根据协议和端口号选定处理请求的Service；Service一旦被选定，Engine也就确定了。 通过在Server中配置多个Service，可以实现通过不同的端口号来访问同一台机器上的不同应用。 根据域名或IP地址选定HostService确定后，Tomcat在Service中寻找名称与域名/IP地址匹配的Host处理该请求，如果没有找到，则使用Engine中指定defaultHost来处理该请求。因为上面的配置文件只有一个Host，因此该Service/Engine的所有请求都交给该Host处理。 根据URI选定Context/WEB应用这点在Context中有介绍。 举例以请求http://localhost:8080/examples/index.html为例，首先通过协议和端口号（HTTP和8080）选定Service，然后通过主机名（localhost）选定Host，然后通过URI（/examples/index.html）选定WEB应用 如何配置多个服务？通过在Server中配置多个Service服务，可以实现通过不同的端口号来访问同一台机器上部署的不同应用。 在server.xml中配置多服务的方法很简单： 复制&lt;Service&gt;，放在当前&lt;Service&gt;后面。 修改端口号：根据需要监听的端口号修改&lt;Connector&gt;元素的port属性，必须保证该端口没有被其他进程占用，否则将会出错。 修改Service和Engine的name属性 修改Host的appBase属性（如WEBapps2） WEB应用仍然使用自动部署 将要部署的WEB应用（WAR包或应用目录）拷贝到新的appBase目录下。 以上面的配置文件为例，可以这样配置多服务： 12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;Server port="8005" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JasperListener" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/opt/project/WEBapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt; &lt;Service name="Catalina2"&gt; &lt;Connector port="8084" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8010" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina2" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="/opt/project/WEBapps2" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 再将原WEBapps下的docs目录拷贝到WEBapps2中，则通过如下两个接口都可以访问docs应用： http://localhost:8080/docs/ http://localhost:8084/docs/ 其他组件除核心组件外，server.xml中还可以配置很多其他组件，具体可以查看Tomcat官方文档 Listener123456&lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt;&lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt;&lt;Listener className="org.apache.catalina.core.JasperListener" /&gt;&lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt;&lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt;&lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; Listener(即监听器)定义的组件，可以在特定事件发生时执行特定的操作；被监听的事件通常是Tomcat的启动和停止。 监听器可以在Server、Engine、Host或Context中，上面配置的的监听器都是在Server中。实际上，本例中定义的6个监听器，都只能存在于Server组件中。监听器不允许内嵌其他组件。 监听器需要配置的最重要的属性是className，该属性规定了监听器的具体实现类，该类必须实现了org.apache.catalina.LifecycleListener接口。 下面依次介绍配置文件中配置的监听器： VersionLoggerListener：当Tomcat启动时，该监听器记录Tomcat、Java和操作系统的信息。该监听器必须是配置的第一个监听器。 AprLifecycleListener：Tomcat启动时，检查APR库，如果存在则加载。APR，即Apache Portable Runtime，是Apache可移植运行库，可以实现高可扩展性、高性能，以及与本地服务器技术更好的集成。 JasperListener：在WEB应用启动之前初始化Jasper，Jasper是JSP引擎，把JVM不认识的JSP文件解析成java文件，然后编译成class文件供JVM使用。 JreMemoryLeakPreventionListener：与类加载器导致的内存泄露有关。 GlobalResourcesLifecycleListener：通过该监听器，初始化\标签中定义的全局JNDI资源；如果没有该监听器，任何全局资源都不能使用。 ThreadLocalLeakPreventionListener：当WEB应用因thread-local导致的内存泄露而要停止时，该监听器会触发线程池中线程的更新。当线程执行完任务被收回线程池时，活跃线程会一个一个的更新。只有当WEB应用(即Context元素)的renewThreadsWhenStoppingContext属性设置为true时，该监听器才有效。 GlobalNamingResources与Realm上面的配置文件中，Engine组件下定义了Realm组件： 123&lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase" /&gt;&lt;/Realm&gt; Realm，可以把它理解成“域”；Realm提供了一种用户密码与WEB应用的映射关系，从而达到角色安全管理的作用。在本例中，Realm的配置使用name为UserDatabase的资源实现。而该资源在Server元素中使用GlobalNamingResources配置： 1234&lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt;&lt;/GlobalNamingResources&gt; GlobalNamingResources元素定义了全局资源，通过配置可以看出，该配置是通过读取/conf/tomcat-users.xml实现的。 Valve1&lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; 单词Valve的意思是“阀门”，在Tomcat中代表了请求处理流水线上的一个组件，Valve可以与Tomcat的容器（Engine、Host或Context）关联。 不同的Valve有不同的特性，下面介绍一下上面出现的AccessLogValve。 AccessLogValve的作用是通过日志记录其所在容器中处理的所有请求，上面的配置文件中，Valve放在Host下，便可以记录该Host处理的所有请求。AssessLogValve记录的日志就是访问日志，每天的请求会写到一个日志文件里。 上面AssessLogValve属性的配置，使用的是默认配置。AssessLogValve中各个属性的作用如下： className:规定了Valve的类型，是最重要的属性 directory:指定日志存储的位置 prefix:指定日志文件的前缀 suffix:指定日志文件的后缀 pattern:指定记录日志的格式，上面各项含义如下： %h:远程主机名或IP地址，如果有nginx等反向代理服务器进行请求分发，该主机名/IP地址代表的是nginx，否则代表的是客户端。 %l:远程逻辑用户名，一律是”-“，可以忽略 %u:授权的远程用户名，如果没有，则是”-“ %t:访问的时间 %r:请求的第一行，即请求的方法（get/post），url，及协议 %s:响应的状态，200、404等 %b:响应的数据量，不包括请求头，如果是0，则是”-“ 除此之外，还有一个常用选项是%D，含义是请求处理的时间（单位是毫秒）]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Fragment 学习总结]]></title>
    <url>%2F2018%2F04%2F02%2FAndroid%20Fragment%20%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>Fragment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python requests库的使用]]></title>
    <url>%2F2018%2F03%2F14%2FPython%20requests%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>requests</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法汇总]]></title>
    <url>%2F2018%2F01%2F28%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[数据结构的一部分重要内容便是排序算法，对于排序之后的数组可以采用快速的 binary search 算法。排序算法多种多样，按类别有插入类、选择类、交换类，还有一些其他的比如归并等等，对于数据量太多内存无法盛放的情况，则有外部排序。度量各种算法的标准主要有，1）稳定性，2）最好/坏情况下的时间复杂度，3）最好/坏情况下的空间复杂度。 接下来一一介绍以上的算法及其性能分析，以下排序方法均是对于长度为 nn 的序列进行排序。 插入类排序直接插入排序直接插入排序从待排序序列中选取一个数，选好一个位置将其插入到有序列表中，不断重复这个过程直到排序完成。 上图展示了直接插入执行的过程，开始假设第 0 个元素有序，对于第 i=1…n−1 个元素，自 i−1 起往前搜索，查找插入位置，同时后移记录，找到合适位置插入即可，可见共进行 n−1 次插入，若数组有序只需进行 n−1 次比较即可，无需移动，所示复杂度为 O(n) ，若数组逆序，则需进行 (n−1)(n−1+1)2(n−1)(n−1+1)2 次比较与移动，复杂度为 O(n2) ,所以最好时间复杂度 O(n) ,最差时间复杂度 O(n2) ,平均时间复杂度为 O(n2) 。由于在原地排序，空间复杂度为 O(1) ，另外该算法没有改变排序前后相同关键字的顺序，所以是稳定的。 代码演示： 1234567891011public void insert_sort(int[] nums)&#123; if(nums == null || nums.length &lt; 2) return; // i = 1 -&gt; n-1 for(int i = 1; i &lt; nums.length; i++)&#123; if(nums[i] &gt;= nums[i - 1]) continue; int pivot = nums[i], j = i - 1; // 待插入 while(j &gt;= 0 &amp;&amp; nums[j] &gt; pivot) nums[j + 1] = nums[j--]; nums[j + 1] = pivot; //j &lt; 0代表插入到最前面 &#125;&#125; 折半插入排序由于排序过程中前边已经有序，所以可以对有序序列进行折半查找，相对直接插入来说，减少了比较次数，但是由于找到插入位置后扔需移动序列中的元素，所以时间复杂度仍为 O(n2) 。折半插入排序中，需要用 binary search 找到插入位置插入即可。若有相同元素，为了保证其稳定性，则找到相同 key 的最后一个，比如说现在序列为 [1,1,1,1,1,3,4,1] ,我们要插入最后一个 1 ，为了保持其稳定性，则需找到最后一个 1 。 这种带有相同元素的 binary search 的代码如下： 123456789101112131415161718192021public int binary_search(int[] nums,int POS, int key) &#123; int low = 0; int high = nums.length - 1; while(low &lt;= high) &#123; int mid = low + (high - low) / 2; //防止溢出 if(nums[mid] == key) &#123; if(POS == -1) &#123; if(mid &gt; 0 &amp;&amp; nums[mid - 1] == nums[mid]) high = mid - 1; else return mid; &#125; else if (POS == 1)&#123; if(mid &lt; nums.length - 1 &amp;&amp; nums[mid + 1] == nums[mid]) low = mid + 1; else return mid; &#125; else return mid; // POS == 0 &#125; else if(nums[mid] &gt; key) &#123; high = mid - 1; &#125; else &#123; low = mid + 1; &#125; &#125; return high; //在 high 之后的元素插入即可&#125; 希尔排序直接插入排序在序列基本有序时，运算量接近线性，所以希尔排序先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。因此希尔排序可理解为增量插入排序，如下图所示： 需要注意的是需要时的增量序列中的任意元素没有除 1 之外的公因子，且最后一个增量必为 1 ，所以在排序中，先给出一个系列间隔，使得待排序数组按这个间隔进行排序，最后来一遍直接插入排序即可。 代码如下： 123456789101112131415161718192021 public void shell_sort(int[] nums) &#123; if(nums == null || nums.length &lt; 2) return; //给定增量序列,， 注意 做自动生成 则增量不能有除 1 以外的公因子 int[] dks = &#123;5,3,1&#125;; for(int dk : dks ) &#123; for(int i = dk; i &lt; nums.length; i++) &#123; if(nums[i] &gt; nums[i - dk]) continue; int pivot = nums[i],j = i - dk; while(j &gt;= 0 &amp;&amp; nums[j] &gt; pivot) &#123; nums[j + dk] = nums[j]; j -= dk; &#125; nums[j+dk] = pivot; &#125; //System.out.println(Arrays.toString(nums)); &#125; &#125;// output :// dk=5 [13, 27, 49, 55, 4, 49, 38, 65, 97, 76]// dk=3 [13, 4, 49, 38, 27, 49, 55, 65, 97, 76]// dk=1 [4, 13, 27, 38, 49, 49, 55, 65, 76, 97] 由于希尔排序的时间复杂度设计一些数学难题，当数组长度 n 在一定范围内，其平均复杂度为 O(n1.3) ，而且是一种不稳定排序。 选择排序简单选择排序选择排序是这样执行的，对于数组 L 中的元素 0…n−1 ，首先找到最小的元素，与 0 交换，找到次小的元素，与 1 交换，重复执行直到结束。如下图所示： 代码如下： 1234567891011121314public void select_sort(int[] nums) &#123; if(nums == null || nums.length &lt; 2) return; for(int i = 0 ; i &lt; nums.length - 1 ; i ++) &#123; int j = i, idx = j; for(; j &lt; nums.length; j ++) &#123; if(nums[j] &lt; nums[idx]) idx = j; &#125; if( i != idx) &#123; int tmp = nums[i]; nums[i] = nums[idx]; nums[idx] = tmp; &#125; &#125;&#125; 选择排序的最好时间复杂度 O(n2) ,最差时间复杂度 O(n2) ,平均时间复杂度为 O(n2) 。由于在原地排序，空间复杂度为 O(1) ，另外注意算法是不稳定的。比如说序列 [5¯,8,5,2,7]，第一次 5¯↔2 ,变为 [2,8,5,5¯,7] ，之后会选择第一个5，这便导致了不稳定的发生。 堆排序堆（Heap）可以看做一颗完全二叉树，其定义如下： 父节点的键值总是大于等于（或者小于等于，对应最大堆或最小堆）左右子节点的键值 每个节点的左右子树都是一个二叉堆 以最大堆为例，输出堆顶的最大元素，使得剩余的 n−1 个元素重新构建一个最大堆，得到大值，反复执行，便能得到一个有序序列，这个过程便是堆排序。可见堆排序需要解决以下两个问题： 将无序序列构造成一个最大堆 输出堆顶元素后，将剩余元素重新调整为一个最大堆 给定待排序数组之后，将其理解为完全二叉树的形式，在该完全二叉树的最后一个非叶子节点开始进行调整，构建堆，之后取走最值元素，调整剩余元素构造的堆，直到完成。 代码如下： 123456789101112131415161718192021222324252627// heap sort 最大堆，会生成从小到大的序列，因为每次取得一个最大的放在数组的最后public void heap_sort(int[] nums) &#123; if (nums == null || nums.length &lt; 2) return; int len = nums.length; //长度 //最后一个非叶子节点 n/2 -&gt; 0 不断调整，使其成为一个最大堆 for(int i = len / 2; i &gt;= 0; --i) head_adjust(nums, i, len - 1); //顶堆元素与最后一个交换，这时只有新的堆顶不满足堆的定义，调整为最大堆即可，然后将堆顶与倒数第二个交换 for(int i = len - 1; i &gt; 0; --i) &#123; int tmp = nums[i]; nums[i]= nums[0]; nums[0] = tmp; head_adjust(nums, 0, i-1); // 这里 i 之后的元素都已经排序好了 &#125; System.out.println(Arrays.toString(nums));&#125;// 针对某个节点调整该堆,根节点从i = 0 开始，所以左右孩子节点分别为 2*i+1 、 2*i+2public void head_adjust(int[] nums, int start ,int end) &#123; int cur = nums[start]; for(int i = 2 * start + 1 ; i &lt;= end ; i *= 2) &#123; if( i + 1 &lt;= end &amp;&amp; nums[i + 1] &gt; nums[i]) i++;// i 为左右孩子较大的 if( cur &gt; nums[i] ) break; // 父节点大于左右孩子 nums[start] = nums[i]; // 交换 父子节点 start = i; // 调整交换过后的子节点 &#125; nums[start] = cur; //将待调整节点的值赋到最后的正确位置上&#125; 堆排序一般适用于 n 值较大的情形，其时间主要耗费在构建堆时的元素的反复筛选上，其最好时间复杂度 O(nlogn) ,最差时间复杂度 O(nlogn) ,平均时间复杂度为 O(nlogn) 。由于在原地排序，空间复杂度为 O(1) ,另外注意 堆排序是不稳定的。虽然其时间复杂度比较低，但一般情况下效率不如快速，归并甚至希尔排序。 交换类排序冒泡排序冒泡比较简单，它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。 冒泡排序算法的运作如下： 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 代码如下： 1234567891011121314151617// 设置一个 flag ，当某次没有发生交换，说明数组已经有序了public void bubble_sort(int[] nums)&#123; if(nums == null || nums.length &lt; 2) return; boolean flag = false; for(int i = nums.length-1 ; i &gt; 0 ; i --)&#123; flag = false; for(int j = 0 ; j &lt; i ; j++)&#123; if(nums[j] &gt; nums[j+1])&#123; int tmp = nums[j+1]; nums[j+1] = nums[j]; nums[j] = tmp; flag = true; &#125; &#125; if (flag == false) break; &#125;&#125; 时间复杂度当有序时最好时间复杂度 O(n) ，最差时间复杂度 O(n2) ，平均时间复杂度为 O(n2) ，为一种稳定排序。 快速排序快速排序，又称划分交换排序，使用分治法策略来把一个序列分为两个子序列。 步骤为： 从数列中挑出一个元素，称为”基准”（pivot）， 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 递归地把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。如下图所示： 代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940public void quick_sort(int[] nums) &#123; if (nums == null || nums.length &lt; 2) return; partion(nums,0,nums.length-1);&#125;//递归版本，随机选取pivotpublic void ramdom_partion(int[] nums,int left ,int right)&#123; if (left &gt;= right) return; //产生 left -right 之间的随机数,并交换到 left 处作为pivot int idx = new Random().nextInt(right-left) + left; int tmp = nums[left]; nums[left] = nums[idx]; nums[idx] = tmp; int pivot = nums[left]; int l = left, r = right; while (l &lt; r) &#123; while (l &lt; r &amp;&amp; nums[r] &gt;= pivot) --r; if (l &lt; r) nums[l] = nums[r]; while (l &lt; r &amp;&amp; nums[l] &lt; pivot) ++l; if (l &lt; r) nums[r] = nums[l]; &#125; nums[l] = pivot; ramdom_partion(nums, left, l - 1); ramdom_partion(nums, l + 1, right);&#125;//递归版本，设置第一个为 pivot public void partion(int[] nums,int left ,int right) &#123; if (left &gt;= right) return; int l = left, r = right; int pivot = nums[left]; // 设置 pivot while (l &lt; r) &#123; while ( l &lt; r &amp;&amp; nums[r] &gt;= pivot) --r; if (l &lt; r ) nums[l] = nums[r]; while ( l &lt; r &amp;&amp; nums[l] &lt; pivot ) ++l; if (l &lt; r ) nums[r] = nums[l]; &#125; nums[l] = pivot; partion(nums, left, l - 1); partion(nums, l + 1, right);&#125; 注意若数组逆序，则 quick sort 退化为 bubble sort ，所以选择 pivot 的时候最好随机选取，以上代码中给出了随机选取的方式，选好后换到第一个即可，最好时间复杂度 O(nlogn) ，最差时间复杂度 O(n2) ，即数组逆序的时候，但是随机选取 pivot 应该不会有这种状况，平均时间复杂度为 O(nlogn) ，空间复杂度因为递归调用，所以操作系统需要对参数进行压栈，当数组逆序是，达到最坏空间复杂度为 O(n) ，一般情况的平均空间复杂度为 O(logn) ，且注意算法是不稳定的。 事实上，快速排序通常明显比其他 O(nlogn) 算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地达成。 归并排序归并排序的思想是这样的，将待排序序列看成是 n 个长度为 1 的有序序列，将相邻的有序表成对归并，得到 n/2 个长度为 2 的有序表；将这些有序序列再次归并，得到 n/4 个长度为 4 的有序序列；如此反复进行下去，最后得到一个长度为 n 的有序序列。如下图所示： 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//merge sort 分三个函数，分别是调用、划分、合并public void merge_sort(int[] nums) &#123; if (nums == null || nums.length &lt; 2) return; sort(nums, 0, nums.length - 1);&#125;//划分区间public void sort(int[] nums, int left, int right) &#123; if (left &gt;= right) return; int mid = left + (right - left) / 2; sort(nums, left, mid); sort(nums, mid+1, right); merge(nums, left, mid, right);&#125;//将 [left...mid] 与 [mid+1...right] 两个序列合并为新的有序序列 public void merge(int [] nums,int left,int mid,int right) &#123; int[] tmp = new int[right - left + 1];//建立额外的空间 int l = left, r = mid+1, k=0; // while (l &lt;= mid &amp;&amp; r &lt;= right) &#123; if (nums[l] &lt;= nums [r]) tmp[k++] = nums[l++]; else tmp[k++] = nums[r++]; &#125; while (l &lt;= mid ) tmp[k++] = nums[l++]; while (r &lt;= right) tmp[k++] = nums[r++]; for (int i = 0; i &lt; tmp.length; i++) nums[left + i] = tmp[i];&#125;链表归并排序：//归并排序算法,类似于数组的归并，思路基本完全一样public ListNode sortList(ListNode head) &#123; if (head == null || head.next == null) return head; ListNode prev = null; ListNode slow = head, fast = head; while(fast != null &amp;&amp; fast.next != null)&#123; prev = slow; // 记录后半部分的头指针 slow = slow.next; fast = fast.next.next; &#125; prev.next = null; // 断开连接 ListNode h1 = sortList(head); ListNode h2 = sortList(slow); return merge(h1, h2);&#125;//归并两个链表的过程public ListNode merge(ListNode h1, ListNode h2) &#123; ListNode fake = new ListNode(0); ListNode tail = fake; while (h1 != null &amp;&amp; h2 != null) &#123; if (h1.val &gt; h2.val) &#123; tail.next = h2; h2 = h2.next; &#125; else &#123; tail.next = h1; h1 = h1.next; &#125; tail = tail.next; &#125; if (h1 != null) tail.next = h1; if (h2 != null) tail.next = h2; return fake.next;&#125; 归并排序最好最坏的时间复杂度均为 O(nlogn) ，空间复杂度也为 O(n) ，且最大的优点是在 O(nlogn) 中他是一种稳定的排序算法。]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 将80端口请求转发到8080]]></title>
    <url>%2F2017%2F12%2F31%2FUbuntu%20%E5%B0%8680%E7%AB%AF%E5%8F%A3%E8%AF%B7%E6%B1%82%E8%BD%AC%E5%8F%91%E5%88%B08080%2F</url>
    <content type="text"><![CDATA[在Ubuntu部署了tomcat，一般会使用非root用户启动，但域名绑定时会直接访问80端口号。众所周知，在unix下，非root用户不能监听1024以上的端口号，这个tomcat服务器就没办法绑定在80端口下。所以这里需要使用linux的端口转发机制，把到80端口的服务请求都转到8080端口上。 安装 iptables-persistent12sudo apt-get updatesudo apt-get install iptables-persistent 添加 80 端口跳转到 8080 规则1sudo iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080 保存跳转规则1sudo iptables-save]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Tomcat</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次奇怪的debug]]></title>
    <url>%2F2017%2F12%2F31%2F%E4%B8%80%E6%AC%A1%E5%A5%87%E6%80%AA%E7%9A%84debug%2F</url>
    <content type="text"><![CDATA[前言第一次在服务器Tomcat上用war包部署项目，但是在部署新的war包时出现了一个奇怪的bug，访问页面时，第一次打开会显示404页面，然后按F5刷新则会显示正常页面。 解决最初先清除了浏览器缓存，重新访问，并没有解决。 然后尝试了重新部署，仍没有解决问题。 ps:我部署的方式极其简单粗暴 idea导出war包，用xshell传到服务器 stop Tomcat 删除Tomcat的webapps目录下之前的war包和文件夹 将war包拷贝到webapps目录下 start Tomcat 后来查到一个办法，删除tomcat中work/Catalina目录下项目同名文件 不过我在目录下没找到同名文件，只有一个localhost（可能是我server.xml文件配置问题？）文件夹，删除之后，再访问，正常显示。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>war部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 简单语法]]></title>
    <url>%2F2017%2F12%2F30%2FMarkdown%20%E7%AE%80%E5%8D%95%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Markdown是一种极简的『标记语言』，将文本转为HTML，本文介绍Markdown基本语法，内容很少，一行语法一行示例。 强调星号与下划线都可以，单是斜体，双是粗体，符号可跨行，符号可加空格 12345**一个人来到田纳西**__毫无疑问__*我做的馅饼是全天下*_最好吃的_ 一个人来到田纳西 毫无疑问 我做的馅饼是全天下 最好吃的 分割线三个或更多-_*，必须单独一行，可含空格 1___ 引用翻译成html就是&lt;blockquote&gt;&lt;/blockquote&gt;，符号后的空格可不要 1&gt;引用 引用 内层符号前的空格必须要 12&gt;引用 &gt;&gt;引用 引用 引用 无序列表 符号之后的空格不能少，-+*效果一样，但不能混合使用，因混合是嵌套列表，内容可超长 12- 无序列表- 无序列表：我很长。我也很长！那比一比啊？比就比！我有这么长，你有我长吗？我有这么这么长！好吧，你赢了！ 无序列表 无序列表：我很长。我也很长！那比一比啊？比就比！我有这么长，你有我长吗？我有这么这么长！好吧，你赢了！ 有序列表数字不能省略但可无序，点号之后的空格不能少 12341. 有序列表2. 有序列表3. 有序列表8. 有序列表 有序列表 有序列表 有序列表 有序列表 嵌套列表-+*可循环使用，但符号之后的空格不能少，符号之前的空格至少为两个 123456- 嵌套列表 + 嵌套列表 + 嵌套列表 - 嵌套列表 * 嵌套列表- 嵌套列表 嵌套列表 嵌套列表 嵌套列表 嵌套列表 嵌套列表 嵌套列表 文字超链：Inline方式1[百度](http://www.baidu.com "百度") 百度 图片超链多个感叹号，Tooltips可省略，要设置大小只能借助HTML标记 1![GitHub Mark](http://github.global.ssl.fastly.net/images/modules/logos_page/GitHub-Mark.png "GitHub Mark") 索引超链：Reference方式索引，[]内可以是任意字符 123![GitHub Octocat][1][1]:http://github.global.ssl.fastly.net/images/modules/logos_page/Octocat.png 自动链接1&lt;http://baidu.com&gt; http://baidu.com 注释1&lt;!-- 注释 --&gt; 其他文本中可直接用html标签，但是要前后加上空行。]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
        <tag>常用命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下常用指令]]></title>
    <url>%2F2017%2F12%2F30%2FUbuntu%E4%B8%8B%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[前言最近租了个服务器，用的是ubuntu17.04版本系统，所以搜集了一部分常用的指令，方便以后查阅。 基本命令常用命令帮助–help简单的帮助 help command 详细的帮助 man command 最详细的帮助 ls 命令（显示当前目录文件）-a 显示全部文件与文件夹，包括隐藏的文件或文件夹 -l 显示详细的文件信息，包括权限，用户，用户组等 -h 将文件大小以方便阅读的形式表示出来，配合-l参数使用，常有奇效 cd 进入其他目录cd /etc/ 从绝对路径进入etc文件夹 cd etc/ 从当前目录进入etc文件夹 cd .. 返回当前目录的上一级目录 cd - 返回上一次所在的目录 cd 或 cd ~ 返回属主目录 tab键 命令补全tab键常用于在你输入了命令的前几个单词时，按下tab键进行补全，如果有多个前面部分相同的命令，则按两次tab键 alias 别名alias ubuntu=”ls” 用于为一个命令取别名，当你输入ubuntu时等价输入了ls命令 apt-get 下载最常用的指令，用于从软件源获取需要的软件 常用参数： update 与你的软件源（在/etc/apt/sources.list中列出）更新软件包列表，换源后需要执行 upgrade 根据update得到的源软件库与本地已经安装的对比，如果需要升级就全部升级 install 安装软件包，可以使用tab键补全软件包的名字 remove 卸载软件包 purge 卸载软件包，同时删除该软件的配置文件 source 从源里下载软件包的源码到当前目录并解压（除非指定-download-only参数） check 用来（自动）修复已安装软件包之间的依赖关系 clean 清除/var/cache/apt/archives/包括其子目录partial/下的所有软件包缓存 autoclean 删除旧版本的软件包缓存 download 下载软件包的二进制包到当前目录 more、less 分页显示文本文件内容head、tail 显示文件头、尾内容| 管道符 连接多个命令将一个命令的标准输出作为另一个命令的标准输入。也就是把几个命令组合起来使用，后一个命令除以前一个命令的结果。 例：grep -r “close” /home/* | more 在home目录下所有文件中查找，包括close的文件，并分页输出。 grep 字符串 在文本文件中查找某个字符串sudo 管理员权限sudo 我们主要用来临时提升权限，主要用以管理员(超级用户)的权限来运行命令，当需要修改当前登录用户力所不能及的文件/目录时需要用sudo 文件操作find 起始目录 -name 查找的文件或目录mkdir 目录名 创建一个目录-p 如果给出的路径中父目录不存在,则同时创建父目录 touch 文件名 .. 创建一个或多个文件rmdir 空目录名 删除一个空目录等同 rm -f rm 文件名 .. 删除一个或多个文件最常用参数: -f 不提示不存在的文件,直接跳过 -i 每个删除动作都提示 -I 删除多个文件(多于3个时)或者递归式删除(对于非空目录)提示一次 -r和-R 递归式删除该目录下的一切东东 -v 显示每个文件的删除动作(个人总是推荐使用此参数,明白你在做什么) 注意：慎用 rm -rf 非空目录名 删除一个非空目录下的一切 mv 源文件或目录 目标文件或目录根据mv命令中的第二个参数类型（是目标文件还是目标目录），mv命令将文件重命名或将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时，源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。 最常用参数: -b 为每个已经存在的目的文件做个备份(防止覆盖) -f 不提示是否覆盖已经存在的目的文件 -i 与-f参数相反 -u 仅当源文件比目的文件更新或者目的文件不存在时候才移动 -v 显示移动文件的进度(个人总是推荐使用此参数,明白你在做什么) cat 文件名 ..把(一个或多个)文件内容(连接)显示到标准输出，当文本文件很小，而且你只是想看下，并不打算用gedit或者vim之类编辑器编辑的时候，可以使用。 find 路经 -name“字符串”查找路经所在范围内满足字符串匹配的文件和目录 最常用参数: -v 列出当前正在执行的步骤 -R 递归式,即改变非空目录下的一切为指定权限 cp 文件名或目录名 拷贝文件或目录最常用参数： -b 为每个已经存在的目的文件作个备份 -d 遇到软链接时不拷贝软链接所指向的文件;拷贝时保留links属性(链接数) -p 保留文件的访问权限,所有者,和时间戳 -R和-r 递归式拷贝(cp过程遇到非空目录才有效),即拷贝目录,子目录,子目录的子目录….. -a 作用同-dpR -s 并不真的做拷贝,而只是为每个文件作软链接(符号链接) -u 仅当源文件比目的文件更新或者目的文件不存在时候才拷贝 ln 源文件或目录 目标文件或目录 为文件建立连接linux的链接分为两种:硬链接和软链接，ln默认建立硬链接，硬链接的意思是一个档案可以有多个名称，而软链接的方式则是产生一个特殊的档案，该档案的内容是指向另一个档案的位置。硬链接是存在同一个文件系统中，而软链接却可以跨越不同的文件系统 注意： ln命令会保持每一处链接文件的同步性，也就是说，不论你改动了哪一处，其它的文件都会发生相同的变化 最常用参数: -s 建立软链接(符号链接,可以理解为win下的快捷方式) -f 如果要建立的链接名已经存在,则删除之 -b 删除，覆盖以前建立的链接 -v 显示详细的处理过程 tar 打包与解包和ps命令一样,tar一般不用单个参数,而是多个参数的组合,记住参数x是解压(extract),c是创建包(create)即可 最常用参数: -xvf 详细列出解包的步骤 -cvf 详细列出打包的步骤 -j 用来说明这是个tar.bz2包,例如tar -xjvf myfile.tar.bz2 -t 列出包中的文件列表 打包时常追加的参数: -r 追加到压缩包中 -u 只把比包中更新的文件追加进去 -h 不把符号链接添加到包中,而是添加此符号链接指向的文件 用户管理/etc/passwd 存储用户账号/etc/group 存储组账号/etc/shadow 存储用户账号的密码/etc/gshadow 存储用户组账号的密码/etc/profile 系统环境变量bash_profile 用户环境变量.bashrc 用户环境变量su user 切换用户，加载配置文件.bashrcsu - user 切换用户，加载配置文件/etc/profile ，加载bash_profileuseradd 创建一个新的用户groupadd 组名 创建一个新的组passwd 用户名 为用户创建密码最常用参数： -d 用户名 删除用户密码也能登陆 -S 用户名 查询用户状态 usermod -l 新用户名 老用户名 为用户改名userdel –r 用户名 删除用户一切chown [-R] owner[:group] {File|Directory} 更改文件的用户及用户组chown root:root filename 如果需要将某一目录下的所有文件都改变其拥有者，可以使用-R参数 chgrp [group] {File|Directory} 更改文件所属组群chgrp root filename chgrp 权限管理三种基本权限 R 读 数值表示为4 W 写 数值表示为2 X 可执行 数值表示为1 例如： -rw-rw-r–一共十个字符，分成四段。 第一个字符“-”表示普通文件；这个位置还可能会出现“l”链接；“d”表示目录 第二三四个字符“rw-”表示当前所属用户的权限，所以用数值表示为4+2=6 第五六七个字符“rw-”表示当前所属组的权限，所以用数值表示为4+2=6 第八九十个字符“r–”表示其他用户权限，所以用数值表示为2 更改权限sudo chmod [u所属用户 g所属组 o其他用户 a所有用户] [+增加权限 -减少权限] [r w x] 目录名 例如：有一个文件filename，权限为“-rw-r—-x”，将权限值改为“-rwxrw-r-x”，用数值表示为765 sudo chmod u+x g+w o+r filename 上面的例子可以用数值表示 sudo chmod 765 filename 系统管理ps，top 列出当前命令的执行状态ps为静态，top为动态(top时’q’退出) 最常用参数(ps多用参数集合,而不是单个参数,并且配合grep使用): -ef 以标准语法列出当前所有进程状态,例如ps -ef | grep eva 列出eva的进程状态 aux 以BSD语法列出 -ejH 列出进程树 -eLf 同时列出线程状态 kill 进程号(PID) 杀死一个进程kill -9 进程号 强制杀死一个进程stat 显示指定文件的详细信息，比ls更详细who 显示在线登陆用户whoami 显示当前操作用户hostname 显示主机名uname 显示系统信息du 查看目录大小 du -h /home带有单位显示目录信息df 查看磁盘大小 df -h 带有单位显示磁盘信息ifconfig 查看网络情况ping 测试网络连通netstat 显示网络状态信息常用参数 -a (all)显示所有选项，默认不显示LISTEN相关 -t (tcp)仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化成数字。 -l 仅列出有在 Listen (监听) 的服務状态 -p 显示建立相关链接的程序名 -r 显示路由信息，路由表 -e 显示扩展信息，例如uid等 -s 按各个协议进行统计 -c 每隔一个固定时间，执行该netstat命令。 注意： LISTEN和LISTENING的状态只有用-a或者-l才能看到 man 功能很多，简单的可以查看命令帮助，如：man lsufw 防火墙常用参数： enable 启动防火墙 status 查看防火墙状态 allow 端口号或服务名 开放指定端口号 allow 22/tcp 只打开使用tcp/ip协议的22端口 disable 关闭防火墙 allow from 192.168.254.254 允许某特定IP delete allow 删除已添加的规则 clear 清屏]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>常用命令</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 数据类型]]></title>
    <url>%2F2017%2F11%2F18%2Fjava%20%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java 的数据类型分为基本数据类型和引用数据类型。 基本数据类型基本数据类型有四类八种，分别是： byte：Java中最小的数据类型，在内存中占8位(bit)，即1个字节，取值范围-128~127，默认值0、 short：短整型，在内存中占16位，即2个字节，取值范围-32768~32717，默认值0、 int：整型，用于存储整数，在内在中占32位，即4个字节，取值范围-2147483648~2147483647，默认值0、 long：长整型，在内存中占64位，即8个字节-2^63~2^63-1，默认值0L； float：浮点型，在内存中占32位，即4个字节，用于存储带小数点的数字（与double的区别在于float类型有效小数点只有6~7位），默认值0、 double：双精度浮点型，用于存储带有小数点的数字，在内存中占64位，即8个字节，默认值0； boolean：布尔类型，占1个字节，用于判断真或假（仅有两个值，即true、false），默认值false； char：字符型，用于存储单个字符，占16位，即2个字节，取值范围0~65535，默认值为空。 这种类型通过如 int a = 3 的形式定义，称为自动变量。值得注意的是，自动变量存的是字面值，不是类的引用，这里的 a 是一个指向 int 类型的引用，指向3这个字面值。这些字面值大小可知，生存期可知，因此会保存在栈中。 另外，栈有一个很重要的特殊性，即数据可以共享。如果我们同时定义12int a = 3; int b = 3; 编译器先处理 int a = 3 ；会在栈中创建一个变量a的引用，然后查找有无字面值为3的地址，如果没有，则开辟一个存放3字面值的地址，然后将a指向3的地址。然后处理 int b = 3 ；创建b的引用后，由于栈中已经有3的字面值，便将b直接指向3的地址。因此，a与b同时指向3。 但是要注意，通过引用修改字面值不会导致另一个指向此字面值的引用的值改变，在字面值被修改时，编译器会重新搜索栈中是否存在被修改后的字面值，如果不存在，则开辟一片空间存放新字面值的地址，如果存在，则直接将引用指向这个地址。 引用数据类型除基本数据类型之外的数据类型都是引用数据类型，其中 String 类是特殊的引用数据类型，这些类型的数据全部存放在堆中，Java 通过 new 关键字来显式告诉编译器，在运行时根据需要动态创建，比较灵活，但是会占用更多的时间。 1Object o = new Object(); 引用数据类型（除String）在创建时可以同时创建一个引用变量，该变量是基本数据类型，存储在栈中，指向引用数据类型在堆中的地址。如果通过一个引用变量修改引用数据类型，则其他指向这个对象的引用也会即刻反映出这些改变。 在方法中，调用时传入的实际参数，如果是基本数据类型，则会传入字面值，而如果是引用数据类型，则传入的是该对象的地址。因此，在被调用方法中对引用数据类型进行操作，调用方法中的引用变量所对应的该对象也会相应变化。 String 类String 类是一种特殊的引用数据类型。可以使用 String str = new String(&quot;asd&quot;); 的方式来创建，也可以使用 String str = &quot;asd&quot;; 的方式来创建。一个字符串对象创建后他的值不能改变，如果改变字符串的值，编译器将会创建一个新的字符串对象，然后把地址指向新地址。 常量池(constant pool)指的是在编译期被确定，并被保存在已编译的.class文件中的一些数据。它包括了关于类、方法、接口等中的常量，也包括字符串常量。因此，对于 String str = &quot;asd&quot;; ，将会保存在常量池中。而对于 String str = new String(&quot;asd&quot;); ，编译器将会创建一个字符串对象，并把 str指向该地址。 12345String s1 = "";String s2 = new String("");System.out.println(s1);System.out.println(s2); 将会打印 12null 1234567String s0 = "asdf"; String s1 = "asdf"; String s2 = "as" + "df"; System.out.println(s0 == s1); System.out.println(s0 == s2); 将会打印 12truetrue 因为这些字符串在编译时就被确定了，其中 String s2 = &quot;as&quot; + &quot;df&quot;; 由多个字符串常量连接而成，因此在编译时就被解析为一个字符串常量，因此结果为true。 1234567String s0 = "asdf";String s1 = new String("asdf");String s2 = "as" + new String("df");System.out.println(s0 == s1);System.out.println(s0 == s2);System.out.println(s1 == s2); 结果为123false false false 其中 s0 是在编译时常量池中的引用， s1 是在运行时创建的对象， s2 因为在编译时无法确定 new String(“df”)，所以也是在运行时创建的对象，其地址与 s1 不同。因此结果为false。 如果想要比较字符串之间的值，则应该使用 equals() 方法。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 堆和栈]]></title>
    <url>%2F2017%2F11%2F17%2Fjava%20%E5%A0%86%E5%92%8C%E6%A0%88%2F</url>
    <content type="text"><![CDATA[栈和堆在 Java 中是用来在内存中存放数据的地方，与 C/C++ 不同， Java 自动管理栈和堆。 栈的存取速度比堆要快，仅次于直接位于 CPU 中的寄存器。但是，存在栈中的数据大小与生存期必须是确定的，缺乏灵活性。堆可以动态的分配内存大小，生存期也可以不先告诉编译器，但是存取速度较慢。 内存Java 的内存分为两种，堆内存和栈内存。 区别栈内存用于存放一些基本类型的变量和对象的引用变量。当在一段代码块中定义一个变量时， Java 就在栈中为这个变量分配内存空间，当超过变量的作用域后，Java 会自动释放掉为该变量分配的内存空间，该内存空间可以立刻被另作他用。 堆内存用于存放由 new 创建的对象和数组。在堆中分配的内存，由 Java 虚拟机自动垃圾回收器来管理。在堆中产生了一个数组或者对象后，还可以在栈中定义一个特殊的变量，这个变量的取值等于数组或者对象在堆内存中的首地址，在栈中的这个特殊的变量就变成了数组或者对象的引用变量，以后就可以在程序中使用栈内存中的引用变量来访问堆中的数组或者对象，引用变量相当于为数组或者对象起的一个别名，或者代号，是一个普通变量，在栈中分配内存，当程序运行到作用域外时释放。 数组和对象本身在堆中分配，在程序运行到使用 new 产生数组或对象的语句所在代码块之外，所占用的内存也不会释放。数组和对象在没有引用变量指向它的时候，将会变成垃圾，不能再被使用，但是仍然占着内存，在随后的一个不确定的时间由垃圾回收器释放。这是 Java 占内存的主要原因。 栈中的变量指向堆中的变量，可以看作是 Java 的指针。 分配策略按照编译原理观点，程序运行时的内存分配有三种策略：静态、栈式、堆式。 静态储存分配指在编译时就能确定每个数据目标在运行时刻的储存空间需求，因此在编译时就可以给他们分配固定的内存空间，这种分配策略要求程序代码中不能有可变数据结构，也不允许有嵌套或者递归的结构出现，因为他们会导致编译程序无法准确计算储存空间需求。 栈式存储分配也可称为动态存储分配，是由一个类似于堆栈的运行栈来实现的。和静态存储分配相反，在栈式存储方案中，程序对数据区的需求在编译时是完全未知的，只有到运行的时候才能够知道，但是规定在运行中进入一个程序模块时，必须知道该程序模块所需的数据区大小才能够为其分配内存.和我们在数据结构所熟知的栈一样，栈式存储分配按照先进后出的原则进行分配。 栈式储存分配要求在过程的入口处必须知道所有的存储需求，而堆式分配则专门负责在编译时或运行时模块入口处都无法确定储存需求的数据结构的内存分配，比如：可变长度串和对象实例，堆由大片的可利用块或空闲块组成，堆中的内存可以按照任意顺序分配和释放。 区别从栈和堆的功能和作用来通俗的比较，堆主要用来存放对象，栈主要用来执行程序。这种不同主要是由于堆和栈的特点决定的： 在 Java 中，所有的方法调用都是通过栈来进行的，所有的局部变量，形式参数都是从栈中分配内存空间。实际上也不是什么分配，只是从栈顶向上用就行。需要注意的是，在分配的时候，比如为一个即将要调用的程序模块分配数据区时，应事先知道这个数据区的大小，也就说是虽然分配是在程序运行时进行的，但是分配的大小多少是确定的，不变的，而这个“大小多少”是在编译时确定的，不是在运行时。 堆是应用程序在运行的时候请求操作系统分配给自己内存，由于从操作系统管理的内存分配，所以在分配和销毁时都要占用时间，因此用堆的效率非常低。但是堆的优点在于，编译器不必知道要从堆里分配多少存储空间，也不必知道存储的数据要在堆里停留多长的时间，因此，用堆保存数据时会得到更大的灵活性。事实上，面向对象的多态性，堆内存分配是必不可少的，因为多态变量所需的存储空间只有在运行时创建了对象之后才能确定。 JVM 中的堆和栈JVM 是基于栈的虚拟机。 JVM 为每个新创建的线程都分配一个栈.也就是说，对于一个Java程序来说，它的运行就是通过对堆栈的操作来完成的。堆栈以帧为单位保存线程的状态。JVM对堆栈只进行两种操作：以帧为单位的压栈和出栈操作。 我们知道，某个线程正在执行的方法称为此线程的当前方法，当前方法使用的帧称为当前帧。当线程激活一个 Java 方法， JVM 就会在线程的 Java 堆栈里新压入一个帧，这个帧自然成为了当前帧。在此方法执行期间，这个帧将用来保存参数，局部变量，中间计算过程和其他数据，这个帧在这里和编译原理中的活动纪录的概念是差不多的。 从 Java 的这种分配机制来看，栈又可以这样理解：栈是 JVM 在建立某个进程时或者线程为这个线程建立的存储区域，该区域具有先进后出的特性。 每一个 Java 应用都唯一对应一个 JVM 实例，每一个实例唯一对应一个堆。应用程序在运行中所创建的所有类实例或数组都放在这个堆中，并由应用所有的线程共享。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gradle 项目中文乱码的解决]]></title>
    <url>%2F2017%2F09%2F27%2FGradle%20%E9%A1%B9%E7%9B%AE%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E7%9A%84%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[前言最近使用 Gradle 构建项目，项目里需要自定义异常，结果发现异常信息乱码。百度了一堆教程也没解决，最后查看 class 文件发现是编译过程中造成的乱码。 在官方文档中发现， Gradle 会根据操作系统选择编码，Windows 中文操作系统的默认编码是GBK，而项目使用的编码格式是UTF-8，最终 Gradle 将UTF-8编码识别为GBK编码，导致了乱码问题。 解决办法在 build.gradle 文件中添加 123tasks.withType(JavaCompile) &#123; options.encoding = "UTF-8" &#125; 这样 Gradle 会将文件识别为UTF-8编码。 其他上面的解决办法需要每个项目都插入一段，有点麻烦，不过还是有其他更简便的办法。就是在 Windows 下新建 GRADLE_OPTS 环境变量，值为 -Dfile.encoding=utf-8。这样在终端中使用的 Gradle 命令便可以识别UTF-8编码格式。 如果是 IDE 进行 Gradle 操作，那么还需要设置IDE的参数。因为我使用的是 idea，这里只介绍 idea 的解决办法。打开 File-&gt;Settings-&gt;Build,Execution,Deployment-&gt;Build Tools-&gt;Gradle，在 Gradle Vm Options 中添加 -Dfile.encoding=utf-8。]]></content>
      <categories>
        <category>Gradle</category>
      </categories>
      <tags>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea 常用快捷键及插件]]></title>
    <url>%2F2017%2F09%2F27%2Fidea%20%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%8F%8A%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[记录下 idea 常用的快捷键，便于以后使用。 快捷键生成代码常用的有fori/sout/psvm+Tab即可生成循环、System.out、main方法等boilerplate样板代码 要输入for(User user : users)只需输入user.for+Tab 要输入Date birthday = user.getBirthday();只需输入user.getBirthday().var+Tab即可。代码标签输入完成后，按Tab，生成代码 Ctrl+Alt+O 优化导入的类和包 Alt+Insert 生成代码(如get,set方法,构造函数等)或者右键（Generate） fori/sout/psvm + Tab Ctrl+Alt+T 生成try catch 或者 Alt+Enter Ctrl + O 重写方法 Ctrl + I 实现方法 Ctrl+Shift+U 大小写转化 Alt+回车 导入包,自动修正 Ctrl+J 自动代码 Ctrl+Shift+J，整合两行为一行 Ctrl+空格 代码提示 Ctrl+Shift+SPACE 自动补全代码 Ctrl+Alt+L 格式化代码 Ctrl+Alt+I 自动缩进 Ctrl+E 最近更改的代码 Ctrl+P 方法参数提示 Ctrl+Q 可以看到当前方法的声明 Shift+F6 重构-重命名 (包、类、方法、变量、甚至注释等) Ctrl+Alt+V 提取变量 查询Ctrl+Shift+Backspace 可以跳转到上次编辑的地 Ctrl+Alt+left/right 前后导航编辑过的地方 Alt+7 靠左窗口显示当前文件的结构 Ctrl+F12 浮动显示当前文件的结构 Alt+F7 找到你的函数或者变量或者类的所有引用到的地方 Ctrl+Alt+F7 找到你的函数或者变量或者类的所有引用到的地方 Ctrl+Shift+Alt+N 查找类中的方法或变量 双击Shift 在项目的所有目录查找文件 Ctrl+N 查找类 Ctrl+Shift+N 查找文件 Ctrl+G 定位行 Ctrl+F 在当前窗口查找文本 Ctrl+Shift+F 在指定窗口查找文本 Ctrl+R 在当前窗口替换文本 Ctrl+Shift+R 在指定窗口替换文本 Alt+Shift+C 查找修改的文件 Ctrl+E 最近打开的文件 F3 向下查找关键字出现位置 Shift+F3 向上一个关键字出现位置 选中文本，按Alt+F3 ，高亮相同文本，F3逐个往下查找相同文本 F4 查找变量来源 Ctrl+Shift+O 弹出显示查找内容 Ctrl+W 选中代码，连续按会有其他效果 F2 或Shift+F2 高亮错误或警告快速定位 Ctrl+Up/Down 光标跳转到第一行或最后一行下 Ctrl+B 快速打开光标处的类或方法 Ctrl+Alt+B 找所有的子类 Ctrl+Shift+B 找变量的类 Ctrl+Shift+上下键 上下移动代码 Ctrl+Alt+ left/right 返回至上次浏览的位置 Ctrl+X 删除行 Ctrl+D 复制行 Ctrl+/ 或 Ctrl+Shift+/ 注释（// 或者/…/ ） Ctrl+H 显示类结构图 Ctrl+Q 显示注释文档 Alt+F1 查找代码所在位置 Alt+1 快速打开或隐藏工程面板 Alt+ left/right 切换代码视图 Alt+ ↑/↓ 在方法间快速移动定位 Alt+6 查找TODO 调试Alt+F8 debug时选中查看值 Alt+Shift+F9 选择 Debug Alt+Shift+F10 选择 Run Ctrl+Shift+F9 编译 Ctrl+Shift+F8 查看断点 F7 步入 Shift+F7 智能步入 Alt+Shift+F7 强制步入 F8 步过 Shift+F8 步出 Alt+Shift+F8 强制步过 Alt+F9 运行至光标处 Ctrl+Alt+F9 强制运行至光标处 F9 恢复程序 Alt+F10 定位到断点 重构Ctrl+Alt+Shift+T 弹出重构菜单 Shift+F6 重命名 F6 移动 F5 复制 Alt+Delete 安全删除 Ctrl+Alt+N 内联 其他Shift+Enter 另起一行 Ctrl+Z 倒退(撤销) Ctrl+Shift+Z 向前(取消撤销) Ctrl+Alt+F12 资源管理器打开文件夹 Alt+F1 查找文件所在目录位置 Shift+Alt+Insert 竖编辑模式 Ctrl+F4 关闭当前窗口 Ctrl+Alt+V 可以引入变量。例如：new String(); 自动导入变量定义 Ctrl+~ 快速切换方案（界面外观、代码风格、快捷键映射等菜单） 插件插件的安装就不多介绍了，主要介绍下常用的插件 Background Image Plus个人很喜欢的一款插件，可以为idea添加背景，安装之后，在打开View选项，就可以看到Set Background Image选项了。 FindBugsFindBugs很多人都并不陌生，Eclipse中有插件可以帮助查找代码中隐藏的bug，IDEA中也有这款插件。 CheckStyle通过检查对代码编码格式，命名约定，Javadoc，类设计等方面进行代码规范和风格的检查，从而有效约束开发人员更好地遵循代码编写规范。 软件安装成功之后，首先要设置规则。可以通过Preferences—&gt;Other Settings —&gt;CheckStyles进行设置，可以直接将文件添加进来，然后就可以对具体的文件进行检查了。 GsonFormatJava开发中，经常有把json格式的内容转成Object的需求，GsonFormat这款插件可以实现该功能。 JrebelJRebel for IntelliJ是一款热部署插件。能够在开发过程中帮助开发者节约大量的部署等待时间，几乎所有的代码改动都不需要重启应用服务器，连Spring增加一个Bean都可以热部署。是一款收费插件，具体设置可以百度。 AceJumpAceJump其实是一款能够代替鼠标的软件，只要安装了这款插件，可以在代码中跳转到任意位置。按快捷键进入 AceJump 模式后（默认是 Ctrl+J），再按任一个字符，插件就会在屏幕中这个字符的所有出现位置都打上标签，你只要再按一下标签的字符，就能把光标移到该位置上。换言之，你要 移动光标时，眼睛一直看着目标位置就行了，根本不用管光标的当前位置。 Key promoterKey promoter这款插件适合新手使用。当你点击鼠标一个功能的时候，可以提示你这个功能快捷键是什么。]]></content>
      <categories>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>idea</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo next主题添加背景]]></title>
    <url>%2F2017%2F09%2F17%2Fhexo%20next%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E8%83%8C%E6%99%AF%2F</url>
    <content type="text"><![CDATA[之前使用hexo next主题时突然想添加背景，百度了一下但没有关于Mist主题的教程，于是自己摸索修改了一下，并在这里记录下来。 添加背景首先，找到根路径下的 themes/next/source/css/_custom/custom.styl 文件，添加 1234567body &#123; background : url(/images/你的背景图片名字) no-repeat; //width : 100%; //height : 100%; //设置容器占满屏幕 //background-size : 100% 100%; //设置图片占满容器 //background-attachment : fixed; //设置图片不随页面移动&#125; 并将背景图片添加到 themes/next/source/images 文件夹里 这里建议使用宽图。 效果 我们会发现导航栏显得不搭，这里在询问了朋友后的解决办法是透明化导航栏 透明化header虚化导航栏有两种方式： 1.在 themes/next/source/css/_common/components/header/header.styl 文件中修改 1.header &#123; background: $head-bg; opacity: 0.7&#125; 我们发现导航栏会变成这样 opacity 属性会将子容器也一并透明化，所以如果使用了next自带的搜索，将会失效无法使用 2.在 themes/next/source/css/_schemes/Mist/_header.styl 中修改 1.header &#123; background: rgba(245, 245, 245, 0.6); &#125; 效果为 因为子容器都有 background 属性，所以子容器不会受到父容器透明化的影响，而搜索功能也能正常使用 修改footer下拉博客会发现，footer 也因为设置了固定颜色而盖住了背景。 这个需要在 themes/next/source/css/_schemes/Mist/index.styl 文件中修改 123456.footer &#123; margin-top: 80px; padding: 10px 0; background-color: rgba(245, 245, 245, 0.6); color: $grey-dim;&#125; 如果想子容器也透明化的话，则在 themes/next/source/css/_common/components/footer/footer.styl 中修改，且不要修改 index.styl 文件 1234567.footer &#123; font-size: 14px; color: $grey-dark; opactiy: 0.7; img &#123; border: none; &#125;&#125; 结束至此，添加背景便完成了。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 反射]]></title>
    <url>%2F2017%2F09%2F12%2FJava%20%E5%8F%8D%E5%B0%84%2F</url>
    <content type="text"><![CDATA[前言第一次接触反射是在学习 Spring 框架的时候，当看到 Spring 通过反射注入对象时感到十分有趣。所以这里系统的学习一下反射机制。 动态语言，是指程序在运行时可以改变其结构：新的函数可以被引进，已有的函数可以被删除等在结构上的变化。比如众所周知的ECMAScript(JavaScript)便是一个动态语言。除此之外如Ruby、Python等也都属于动态语言，而C、C++等语言则不属于动态语言。(引自: 百度百科) 概念主要是指程序可以访问，检测和修改它本身状态或行为的一种能力，并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。 反射是java中一种强大的工具，能够使我们很方便的创建灵活的代码，这些代码可以再运行时装配，无需在组件之间进行源代码链接。但是反射使用不当会成本很高！ 通俗说就是 1.可以于运行时加载,探知和使用编译期间完全未知的类 2.程序在运行状态中, 可以动态加载一个只有名称的类, 对于任意一个已经加载的类,都能够知道这个类的所有属性和方法; 对于任意一个对象,都能调用他的任意一个方法和属性 3.加载完类之后, 在堆内存中会产生一个Class类型的对象(一个类只有一个Class对象), 这个对象包含了完整的类的结构信息,而且这个Class对象就像一面镜子,透过这个镜子看到类的结构,所以被称之为:反射。 使用的类通过查询api可以发现使用了四个类，分别对应类的本身，类的构造方法，类的方法，类的属性。 java.lang.Class;Class 类的实例表示正在运行的 Java 应用程序中的类和接口。枚举是一种类，注释是一种接口。每个数组属于被映射为 Class 对象的一个类，所有具有相同元素类型和维数的数组都共享该 Class 对象。基本的 Java 类型（boolean、byte、char、short、int、long、float 和 double）和关键字 void 也表示为 Class 对象。 Class 没有公共构造方法。Class 对象是在加载类时由 Java 虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的。 获取的方式有三种： 1.对象的getClass()方法; 123456public class TestClass&#123; void printClassName(Object obj) &#123; System.out.println("The class of " + obj + " is " + obj.getClass().getName()); &#125;&#125; 2.类的.class(最安全/性能最好)属性; 123456public class TestClass&#123; void printClassName() &#123; System.out.println("The class of Object " + "is " + Object.class.getName()); &#125;&#125; 3.运用Class.forName(String className)动态加载类,className需要是类的全限定名(最常用). 123456public class TestClass&#123; void printClassName() throws ClassNotFoundException &#123; System.out.println("The class of Object " + "is" + Class.forName("java.lang.Object").getName()); &#125;&#125; 通过Class获取信息常用的有： 1.获取方法 Method getMethod(String name, Class&lt;?&gt;... parameterTypes) 2.获取属性 Field getField(String name) 3.获取构造器 Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 4.获取内部类 Class&lt;?&gt;[] getDeclaredClasses() 5.获取外部类 Class&lt;?&gt; getDeclaringClass() 1234567891011121314151617181920212223242526272829303132package Test;/** * Created by ly on 2017/9/12 */public class TestClass &#123; class A&#123; &#125; public static void main(String[] args) &#123; test(); test2(); &#125; static void test()&#123; Class testClass = TestClass.class; System.out.println(testClass.getName()); Class[] declaredClass = testClass.getDeclaredClasses(); for (Class c: declaredClass) &#123; System.out.println(c.getName()); &#125; &#125; static void test2()&#123; Class AClass = A.class; System.out.println(AClass); Class declaredClass = AClass.getDeclaringClass(); System.out.println(declaredClass.getName()); &#125;&#125; 运行结果： test.TestClass test.TestClass$A class test.TestClass$A test.TestClass java.lang.reflect.Method;Method 提供关于类或接口上单独某个方法（以及如何访问该方法）的信息。所反映的方法可能是类方法或实例方法（包括抽象方法）。 Method 允许在匹配要调用的实参与底层方法的形参时进行扩展转换；但如果要进行收缩转换，则会抛出 IllegalArgumentException。 获取Method通过Class下的方法 1.Method getMethod(String name, Class&lt;?&gt;... parameterTypes) //返回一个 Method 对象，它反映此 Class 对象所表示的类或接口的指定公共成员方法。 name - 方法名 parameterTypes - 参数列表 2.Method[] getMethods() //返回一个包含某些 Method 对象的数组，这些对象反映此 Class 对象所表示的类或接口（包括那些由该类或接口声明的以及从超类和超接口继承的那些的类或接口）的公共 member 方法。数组类返回从 Object 类继承的所有（公共）member 方法。返回数组中的元素没有排序，也没有任何特定的顺序。如果此 Class 对象表示没有公共成员方法的类或接口，或者表示一个基本类型或 void，则此方法返回长度为 0 的数组。 调用方法Object invoke(Object obj, Object... args) obj - 从中调用底层方法的对象 args - 用于方法调用的参数 对带有指定参数的指定对象调用由此 Method 对象表示的底层方法。个别参数被自动解包，以便与基本形参相匹配，基本参数和引用参数都随需服从方法调用转换。 如果底层方法是静态的，那么可以忽略指定的 obj 参数。该参数可以为 null。 如果底层方法所需的形参数为 0，则所提供的 args 数组长度可以为 0 或 null。 如果底层方法是实例方法，则使用动态方法查找来调用它，这一点记录在 Java Language Specification, Second Edition 的第 15.12.4.4 节中；在发生基于目标对象的运行时类型的重写时更应该这样做。 如果底层方法是静态的，并且尚未初始化声明此方法的类，则会将其初始化。 如果方法正常完成，则将该方法返回的值返回给调用者；如果该值为基本类型，则首先适当地将其包装在对象中。但是，如果该值的类型为一组基本类型，则数组元素不 被包装在对象中；换句话说，将返回基本类型的数组。如果底层方法返回类型为 void，则该调用返回 null。 1234567public class TestClass&#123; public void test() throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; Class c = Object.class; Method method = c.getMethod("toString"); method.invoke(c.newInstance()); &#125;&#125; java.lang.reflect.Field;Field 提供有关类或接口的单个字段的信息，以及对它的动态访问权限。反射的字段可能是一个类（静态）字段或实例字段。 获取Field通过Class下的方法 1.Field getField(String name) //返回一个 Field 对象，它反映此 Class 对象所表示的类或接口的指定公共成员字段。 name - 字段名 2.Field[] getFields()//返回一个包含某些 Field 对象的数组，这些对象反映此 Class 对象所表示的类或接口的所有可访问公共字段。返回数组中的元素没有排序，也没有任何特定的顺序。如果类或接口没有可访问的公共字段，或者表示一个数组类、一个基本类型或 void，则此方法返回长度为 0 的数组。 获取Field上的值Object get(Object obj) 返回指定对象上此 Field 表示的字段的值。如果该值是一个基本类型值，则自动将其包装在一个对象中。 底层字段的值是按以下方式获得的： 如果底层字段是一个静态字段，则忽略 obj 变量；它可能为 null。 否则，底层字段是一个实例字段。如果指定的 obj 变量为 null，则该方法将抛出一个 NullPointerException。如果指定对象不是声明底层字段的类或接口的实例，则该方法将抛出一个 IllegalArgumentException。 如果此 Field 对象强制实施 Java 语言访问控制，并且底层字段是不可访问的，则该方法将抛出一个 IllegalAccessException。如果底层字段是静态的，并且声明该字段的类尚未初始化，则初始化这个类。 否则，从底层实例字段或静态字段中获取该值。如果该字段是一个基本类型字段，则在返回前将该值包装在一个对象中，否则照原样返回。 如果字段隐藏在 obj 的类型中，则根据前面的规则获得字段的值。 java.lang.reflect.Constructor;Constructor 提供关于类的单个构造方法的信息以及对它的访问权限。 获取Constructor通过Class下的方法 1.Constructor&lt;T&gt; getConstructor(Class&lt;?&gt;... parameterTypes) 返回一个 Constructor 对象，它反映此 Class 对象所表示的类的指定公共构造方法。parameterTypes 参数是 Class 对象的一个数组，这些 Class 对象按声明顺序标识构造方法的形参类型。 如果此 Class 对象表示非静态上下文中声明的内部类，则形参类型作为第一个参数包括显示封闭的实例。 要反映的构造方法是此 Class 对象所表示的类的公共构造方法，其形参类型与 parameterTypes 所指定的参数类型相匹配。 2.Constructor&lt;?&gt;[] getConstructors() 返回一个包含某些 Constructor 对象的数组，这些对象反映此 Class 对象所表示的类的所有公共构造方法。如果该类没有公共构造方法，或者该类是一个数组类，或者该类反映一个基本类型或 void，则返回一个长度为 0 的数组。 注意，此方法返回 Constructor 对象的数组（即取自此类构造方法的数组）时，此方法的返回类型是 Constructor&lt;?&gt;[]，不是 预期的 Constructor[]。此少量信息的返回类型是必需的，因为从此方法返回之后，该数组可能被修改以保存不同类的 Constructor 对象，而这将违反 Constructor[] 的类型保证。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC 配置及常用注解]]></title>
    <url>%2F2017%2F09%2F10%2FSpring%20MVC%20%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Spring MVC 作为目前最主流的MVC框架之一，需要程序员熟练掌握。 而使用注解可以大大简化配置的流程，减少工作量。 所以这里简单讲解Spring MVC注解的配置和常用注解。 配置jar包引入 使用Gradle compile ‘org.springframework:spring-context:4.2.5.RELEASE’ compile ‘org.springframework:spring-webmvc:4.2.5.RELEASE’ web.xml配置 SpringMVC是一个基于DispatcherServlet的MVC框架，每一个请求最先访问的都是DispatcherServlet，DispatcherServlet负责转发每一个Request请求给相应的Handler，Handler处理以后再返回相应的视图(View)和模型(Model)，返回的视图和模型都可以不指定，即可以只返回Model或只返回View或都不返回。 DispatcherServlet是继承自HttpServlet的，既然SpringMVC是基于DispatcherServlet的，那么我们先来配置一下DispatcherServlet，好让它能够管理我们希望它管理的内容。HttpServlet是在web.xml文件中声明的。 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;!-- 指定Spring Bean的配置文件所在目录 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:context.xml&lt;/param-value&gt; &lt;!-- 默认是/WEB-INF/applicationContext.xml --&gt; &lt;/context-param&gt; &lt;!-- Spring配置 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- spring mvc配置 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:mvc.xml&lt;/param-value&gt; &lt;!-- 默认是/WEB-INF/[servlet名字]-servlet.xml --&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; ContextLoaderListener指定了IOC容器初始化的方法 Spring MVC配置 123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:util="http://www.springframework.org/schema/util" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!-- 启用spring mvc 注解 --&gt; &lt;context:annotation-config /&gt; &lt;!-- 设置使用注解的类所在的jar包 --&gt; &lt;context:component-scan base-package="controller"/&gt; &lt;!-- 对转向页面的路径解析。prefix：前缀， suffix：后缀 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver" p:prefix="/jsp/" p:suffix=".jsp" /&gt;&lt;/beans&gt; 使用注解 对你的Controller类使用@Controller注解进行标记。 常用注解@Controller 在SpringMVC 中，控制器Controller 负责处理由DispatcherServlet 分发的请求，它把用户请求的数据经过业务处理层处理之后封装成一个Model ，然后再把该Model 返回给对应的View 进行展示。在SpringMVC 中提供了一个非常简便的定义Controller 的方法，你无需继承特定的类或实现特定的接口，只需使用@Controller 标记一个类是Controller ，然后使用@RequestMapping 和@RequestParam 等一些注解用以定义URL 请求和Controller 方法之间的映射，这样的Controller 就能被外界访问到。此外Controller 不会直接依赖于HttpServletRequest 和HttpServletResponse 等HttpServlet 对象，它们可以通过Controller 的方法参数灵活的获取到。 @Controller 用于标记在一个类上，使用它标记的类就是一个SpringMVC Controller 对象。分发处理器将会扫描使用了该注解的类的方法，并检测该方法是否使用了@RequestMapping 注解。@Controller 只是定义了一个控制器类，而使用@RequestMapping 注解的方法才是真正处理请求的处理器。单单使用@Controller 标记在一个类上还不能真正意义上的说它就是SpringMVC 的一个控制器类，因为这个时候Spring 还不认识它。那么要如何做Spring 才能认识它呢？这个时候就需要我们把这个控制器类交给Spring 来管理。有两种方式： 在SpringMVC 的配置文件中定义MyController 的bean 对象。 在SpringMVC 的配置文件中告诉Spring 该到哪里去找标记为@Controller 的Controller 控制器。 1234&lt;!--方式一--&gt;&lt;bean class="com.host.app.web.controller.MyController"/&gt;&lt;!--方式二--&gt;&lt; context:component-scan base-package = "com.host.app.web" /&gt;//路径写到controller的上一层(扫描包详解见下面浅析) @RequestMapping RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。 RequestMapping注解有六个属性。 value : 指定请求的实际地址，指定的地址可以是URI Template 模式（后面将会说明）; method : 指定请求的method类型， GET、POST、PUT、DELETE等; consumes : 指定处理请求的提交内容类型（Content-Type），例如application/json, text/html; produces : 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回; params : 指定request中必须包含某些参数值是，才让该方法处理。 headers : 指定request中必须包含某些指定的header值，才能让该方法处理请求。 使用 @RequestMapping 来映射 Request 请求与处理器 方式一、通过常见的类路径和方法路径结合访问controller方法 方式二、使用url模板 123456789101112@Controller@RequestMapping ( "/test/&#123;variable1&#125;" )public class MyController &#123; @RequestMapping ( "/showView/&#123;variable2&#125;" ) public ModelAndView showView( @PathVariable("variable1") String variable1, @PathVariable ("variable2") int variable2) &#123; ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName( "viewName" ); modelAndView.addObject( " 需要放到 model 中的属性名称 " , " 对应的属性值，它是一个对象 " ); return modelAndView; &#125;&#125; URI 模板就是在 URI 中给定一个变量，然后在映射的时候动态的给该变量赋值。如URI 模板http://localhost/app/{variable1}/index.html ，这个模板里面包含一个变量variable1 ，那么当我们请求http://localhost/app/hello/index.html 的时候，该URL 就跟模板相匹配，只是把模板中的variable1 用hello 来取代。这个变量在SpringMVC 中是使用@PathVariable 来标记的。在SpringMVC 中，我们可以使用@PathVariable 来标记一个Controller 的处理方法参数，表示该参数的值将使用URI 模板中对应的变量的值来赋值。 代码中我们定义了两个URI 变量，一个是控制器类上的variable1 ，一个是showView 方法上的variable2 ，然后在showView 方法的参数里面使用@PathVariable 标记使用了这两个变量。所以当我们使用/test/hello/showView/2.do 来请求的时候就可以访问到MyController 的showView 方法，这个时候variable1 就被赋予值hello ，variable2 就被赋予值2 ，然后我们在showView 方法参数里面标注了参数variable1 和variable2 是来自访问路径的path 变量，这样方法参数variable1 和variable2 就被分别赋予hello 和2 。方法参数variable1 是定义为String 类型，variable2 是定义为int 类型，像这种简单类型在进行赋值的时候Spring 是会帮我们自动转换的。 在上面的代码中我们可以看到在标记variable1 为path 变量的时候我们使用的是@PathVariable ，而在标记variable2 的时候使用的是@PathVariable(“variable2”) 。这两者有什么区别呢？第一种情况就默认去URI 模板中找跟参数名相同的变量，但是这种情况只有在使用debug 模式进行编译的时候才可以，而第二种情况是明确规定使用的就是URI 模板中的variable2 变量。当不是使用debug 模式进行编译，或者是所需要使用的变量名跟参数名不相同的时候，就要使用第二种方式明确指出使用的是URI 模板中的哪个变量。 除了在请求路径中使用URI 模板，定义变量之外，@RequestMapping 中还支持通配符“* ”。如下面的代码我就可以使用/myTest/whatever/wildcard.do 访问到Controller 的testWildcard 方法。 123456789@Controller@RequestMapping ( "/myTest" )public class MyController &#123; @RequestMapping ( "*/wildcard" ) public String testWildcard() &#123; System. out .println( "wildcard------------" ); return "wildcard" ; &#125; &#125; params属性12345@RequestMapping (value= "testParams" , params=&#123; "param1=value1" , "param2" , "!param3" &#125;)public String testParams() &#123; System. out .println( "test Params..........." ); return "testParams" ;&#125; 用@RequestMapping 的params 属性指定了三个参数，这些参数都是针对请求参数而言的，它们分别表示参数param1 的值必须等于value1 ，参数param2 必须存在，值无所谓，参数param3 必须不存在，只有当请求/testParams.do 并且满足指定的三个参数条件的时候才能访问到该方法。所以当请求/testParams.do?param1=value1&amp;param2=value2 的时候能够正确访问到该testParams 方法，当请求/testParams.do?param1=value1&amp;param2=value2&amp;param3=value3 的时候就不能够正常的访问到该方法，因为在@RequestMapping 的params 参数里面指定了参数param3 是不能存在的。 method属性1234@RequestMapping (value= "testMethod" , method=&#123;RequestMethod. GET , RequestMethod. DELETE &#125;)public String testMethod() &#123; return "method" ;&#125; 在上面的代码中就使用method 参数限制了以GET 或DELETE 方法请求/testMethod 的时候才能访问到该Controller 的testMethod 方法。 headers属性1234@RequestMapping (value= "testHeaders" , headers=&#123; "host=localhost" , "Accept" &#125;)public String testHeaders() &#123; return "headers" ;&#125; headers 属性的用法和功能与params 属性相似。在上面的代码中当请求/testHeaders.do 的时候只有当请求头包含Accept 信息，且请求的host 为localhost 的时候才能正确的访问到testHeaders 方法。 @RequestMapping 标记的处理器方法支持的方法参数和返回类型 1.支持的方法参数类型 （1）HttpServlet 对象，主要包括HttpServletRequest 、HttpServletResponse 和HttpSession 对象。 这些参数Spring 在调用处理器方法的时候会自动给它们赋值，所以当在处理器方法中需要使用到这些对象的时候，可以直接在方法上给定一个方法参数的申明，然后在方法体里面直接用就可以了。但是有一点需要注意的是在使用HttpSession 对象的时候，如果此时HttpSession 对象还没有建立起来的话就会有问题。 （2）Spring 自己的WebRequest 对象。 使用该对象可以访问到存放在HttpServletRequest 和HttpSession 中的属性值。 （3）InputStream 、OutputStream 、Reader 和Writer 。 InputStream 和Reader 是针对HttpServletRequest 而言的，可以从里面取数据；OutputStream 和Writer 是针对HttpServletResponse 而言的，可以往里面写数据。 （4）使用@PathVariable 、@RequestParam 、@CookieValue 和@RequestHeader 标记的参数。 （5）使用@ModelAttribute 标记的参数。 （6）java.util.Map 、Spring 封装的Model 和ModelMap 。 这些都可以用来封装模型数据，用来给视图做展示。 （7）实体类。 可以用来接收上传的参数。 （8）Spring 封装的MultipartFile 。 用来接收上传文件的。 （9）Spring 封装的Errors 和BindingResult 对象。 这两个对象参数必须紧接在需要验证的实体对象参数之后，它里面包含了实体对象的验证结果。 2.支持的返回类型 （1）一个包含模型和视图的ModelAndView 对象。 （2）一个模型对象，这主要包括Spring 封装好的Model 和ModelMap ，以及java.util.Map ，当没有视图返回的时候视图名称将由RequestToViewNameTranslator 来决定。 （3）一个View 对象。这个时候如果在渲染视图的过程中模型的话就可以给处理器方法定义一个模型参数，然后在方法体里面往模型中添加值。 （4）一个String 字符串。这往往代表的是一个视图名称。这个时候如果需要在渲染视图的过程中需要模型的话就可以给处理器方法一个模型参数，然后在方法体里面往模型中添加值就可以了。 （5）返回值是void 。这种情况一般是我们直接把返回结果写到HttpServletResponse 中了，如果没有写的话，那么Spring 将会利用RequestToViewNameTranslator 来返回一个对应的视图名称。如果视图中需要模型的话，处理方法与返回字符串的情况相同。 （6）如果处理器方法被注解@ResponseBody 标记的话，那么处理器方法的任何返回类型都会通过HttpMessageConverters 转换之后写到HttpServletResponse 中，而不会像上面的那些情况一样当做视图或者模型来处理。 （7）除以上几种情况之外的其他任何返回类型都会被当做模型中的一个属性来处理，而返回的视图还是由RequestToViewNameTranslator 来决定，添加到模型中的属性名称可以在该方法上用@ModelAttribute(“attributeName”) 来定义，否则将使用返回类型的类名称的首字母小写形式来表示。使用@ModelAttribute 标记的方法会在@RequestMapping 标记的方法执行之前执行。 @Resource 和 @Autowired @Resource和@Autowired都是做bean的注入时使用，其实@Resource并不是Spring的注解，它的包是javax.annotation.Resource，需要导入，但是Spring支持该注解的注入。 共同点 两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。 不同点 (1) @Autowired @Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。 12345678910public class TestServiceImpl &#123; // 下面两种@Autowired只要使用一种即可 @Autowired private UserDao userDao; // 用于字段上 @Autowired public void setUserDao(UserDao userDao) &#123; // 用于属性的方法上 this.userDao = userDao; &#125;&#125; @Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。如下： 12345public class TestServiceImpl &#123; @Autowired @Qualifier("userDao") private UserDao userDao; &#125; (2) @Resource @Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。 12345678910public class TestServiceImpl &#123; // 下面两种@Resource只要使用一种即可 @Resource(name="userDao") private UserDao userDao; // 用于字段上 @Resource(name="userDao") public void setUserDao(UserDao userDao) &#123; // 用于属性的setter方法上 this.userDao = userDao; &#125;&#125; 注：最好是将@Resource放在setter方法上，因为这样更符合面向对象的思想，通过set、get去操作属性，而不是直接去操作属性。 @Resource装配顺序： ①如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常。 ②如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常。 ③如果指定了type，则从上下文中找到类似匹配的唯一bean进行装配，找不到或是找到多个，都会抛出异常。 ④如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。 @Resource的作用相当于@Autowired，只不过@Autowired按照byType自动注入。 @ModelAttribute 和 @SessionAttributes 该Controller的所有方法在调用前，先执行此@ModelAttribute方法，可用于注解和方法参数中，可以把这个@ModelAttribute特性，应用在BaseController当中，所有的Controller继承BaseController，即可实现在调用Controller时，先执行@ModelAttribute方法。 @SessionAttributes即将值放到session作用域中，写在class上面。 @SessionAttributes @SessionAttributes: 该注解用来绑定HttpSession中的attribute对象的值，便于在方法中的参数里使用。 该注解有value、types两个属性，可以通过名字和类型指定要使用的attribute 对象； 123456@Controller @RequestMapping("/editPet.do") @SessionAttributes("pet") public class EditPetForm &#123; // ... &#125; 2.@ModelAttribute 该注解有两个用法，一个是用于方法上，一个是用于参数上； 用于方法上时： 通常用来在处理@RequestMapping之前，为请求绑定需要从后台查询的model； 用于参数上时： 用来通过名称对应，把相应名称的值绑定到注解的参数bean上；要绑定的值来源于： A） @SessionAttributes 启用的attribute 对象上； B） @ModelAttribute 用于方法上时指定的model对象； C） 上述两种情况都没有时，new一个需要绑定的bean对象，然后把request中按名称对应的方式把值绑定到bean中。 用到方法上1234@ModelAttribute public Account addAccount(@RequestParam String number) &#123; return accountManager.findAccount(number); &#125; 这种方式实际的效果就是在调用@RequestMapping的方法之前，为request对象的model里put（“account”， Account）。 用在参数上1234@RequestMapping(value="/owners/&#123;ownerId&#125;/pets/&#123;petId&#125;/edit", method = RequestMethod.POST) public String processSubmit(@ModelAttribute Pet pet) &#123; &#125; 首先查询 @SessionAttributes有无绑定的Pet对象，若没有则查询@ModelAttribute方法层面上是否绑定了Pet对象，若没有则将URI template中的值按对应的名称绑定到Pet对象的各属性上。 3.使用 @ModelAttribute 和 @SessionAttributes 传递和保存数据 当 @ModelAttribute 标记在方法上的时候，该方法将在处理器方法执行之前执行，然后把返回的对象存放在 session 或模型属性中，属性名称可以使用 @ModelAttribute(“attributeName”) 在标记方法的时候指定，若未指定，则使用返回类型的类名称（首字母小写）作为属性名称。关于 @ModelAttribute 标记在方法上时对应的属性是存放在 session 中还是存放在模型中，我们来做一个实验，看下面一段代码。 12345678910111213141516171819202122232425262728293031@Controller@RequestMapping ( "/myTest" )public class MyController &#123; @ModelAttribute ( "hello" ) public String getModel() &#123; System. out .println( "-------------Hello---------" ); return "world" ; &#125; @ModelAttribute ( "intValue" ) public int getInteger() &#123; System. out .println( "-------------intValue---------------" ); return 10; &#125; @RequestMapping ( "sayHello" ) public void sayHello( @ModelAttribute ( "hello" ) String hello, @ModelAttribute ( "intValue" ) int num, @ModelAttribute ( "user2" ) User user, Writer writer, HttpSession session) throws IOException &#123; writer.write( "Hello " + hello + " , Hello " + user.getUsername() + num); writer.write( "\r" ); Enumeration enume = session.getAttributeNames(); while (enume.hasMoreElements()) writer.write(enume.nextElement() + "\r" ); &#125; @ModelAttribute ( "user2" ) public User getUser()&#123; System. out .println( "---------getUser-------------" ); return new User(3, "user2" ); &#125;&#125; 当我们请求 /myTest/sayHello.do 的时候使用 @ModelAttribute 标记的方法会先执行，然后把它们返回的对象存放到模型中。最终访问到 sayHello 方法的时候，使用 @ModelAttribute 标记的方法参数都能被正确的注入值。执行结果如下所示： Hello world,Hello user210 由执行结果我们可以看出来，此时 session 中没有包含任何属性，也就是说上面的那些对象都是存放在模型属性中，而不是存放在 session 属性中。那要如何才能存放在 session 属性中呢？这个时候我们先引入一个新的概念 @SessionAttributes ，它的用法会在讲完 @ModelAttribute 之后介绍，这里我们就先拿来用一下。我们在 MyController 类上加上 @SessionAttributes 属性标记哪些是需要存放到 session 中的。看下面的代码： 1234567891011121314151617181920212223242526272829303132333435@Controller@RequestMapping ( "/myTest" )@SessionAttributes (value=&#123; "intValue" , "stringValue" &#125;, types=&#123;User. class &#125;)public class MyController &#123; @ModelAttribute ( "hello" ) public String getModel() &#123; System. out .println( "-------------Hello---------" ); return "world" ; &#125; @ModelAttribute ( "intValue" ) public int getInteger() &#123; System. out .println( "-------------intValue---------------" ); return 10; &#125; @RequestMapping ( "sayHello" ) public void sayHello(Map&lt;String, Object&gt; map, @ModelAttribute ( "hello" ) String hello, @ModelAttribute ( "intValue" ) int num, @ModelAttribute ( "user2" ) User user, Writer writer, HttpServletRequest request) throws IOException &#123; map.put( "stringValue" , "String" ); writer.write( "Hello " + hello + " , Hello " + user.getUsername() + num); writer.write( "\r" ); HttpSession session = request.getSession(); Enumeration enume = session.getAttributeNames(); while (enume.hasMoreElements()) writer.write(enume.nextElement() + "\r" ); System. out .println(session); &#125; @ModelAttribute ( "user2" ) public User getUser() &#123; System. out .println( "---------getUser-------------" ); return new User(3, "user2" ); &#125;&#125; 在上面代码中我们指定了属性为 intValue 或 stringValue 或者类型为 User 的都会放到 Session中，利用上面的代码当我们访问 /myTest/sayHello.do 的时候，结果如下： Hello world,Hello user210 仍然没有打印出任何 session 属性，这是怎么回事呢？怎么定义了把模型中属性名为 intValue 的对象和类型为 User 的对象存到 session 中，而实际上没有加进去呢？难道我们错啦？我们当然没有错，只是在第一次访问 /myTest/sayHello.do 的时候 @SessionAttributes 定义了需要存放到 session 中的属性，而且这个模型中也有对应的属性，但是这个时候还没有加到 session 中，所以 session 中不会有任何属性，等处理器方法执行完成后 Spring 才会把模型中对应的属性添加到 session 中。所以当请求第二次的时候就会出现如下结果： Hello world,Hello user210 user2 intValue stringValue 当 @ModelAttribute 标记在处理器方法参数上的时候，表示该参数的值将从模型或者 Session 中取对应名称的属性值，该名称可以通过 @ModelAttribute(“attributeName”) 来指定，若未指定，则使用参数类型的类名称（首字母小写）作为属性名称。 @PathVariable 用于将请求URL中的模板变量映射到功能处理方法的参数上，即取出url模板中的变量作为参数。若方法参数名称和需要绑定的uri template中变量名称不一致，需要在@PathVariable(“name”)指定uri template中的名称。 123456789101112131415161718192021@Controller public class TestController &#123; @RequestMapping(value="/user/&#123;userId&#125;/roles/&#123;roleId&#125;",method = RequestMethod.GET) public String getLogin(@PathVariable("userId") String userId, @PathVariable("roleId") String roleId)&#123; System.out.println("User Id : " + userId); System.out.println("Role Id : " + roleId); return "hello"; &#125; @RequestMapping(value="/product/&#123;productId&#125;",method = RequestMethod.GET) public String getProduct(@PathVariable("productId") String productId)&#123; System.out.println("Product Id : " + productId); return "hello"; &#125; @RequestMapping(value="/javabeat/&#123;regexp1:[a-z-]+&#125;", method = RequestMethod.GET) public String getRegExp(@PathVariable("regexp1") String regexp1)&#123; System.out.println("URI Part 1 : " + regexp1); return "hello"; &#125; &#125; @RequestParam @RequestParam主要用于在SpringMVC后台控制层获取参数，类似一种是request.getParameter(“name”)，它有三个常用参数：defaultValue = “0”, required = false, value = “isApp”；defaultValue 表示设置默认值，required 通过boolean设置是否是必须要传入的参数，value 值表示接受的传入的参数类型。 A）常用来处理简单类型的绑定，通过Request.getParameter() 获取的String可直接转换为简单类型的情况（ String–&gt; 简单类型的转换操作由ConversionService配置的转换器来完成）；因为使用request.getParameter()方式获取参数，所以可以处理get 方式中queryString的值，也可以处理post方式中 body data的值； B）用来处理Content-Type: 为 application/x-www-form-urlencoded编码的内容，提交方式GET、POST； 1234567891011@Controller @RequestMapping("/pets") @SessionAttributes("pet") public class EditPetForm &#123; @RequestMapping(method = RequestMethod.GET) public String setupForm(@RequestParam("petId") int petId, ModelMap model) &#123; Pet pet = this.clinic.loadPet(petId); model.addAttribute("pet", pet); return "petForm"; &#125;&#125; @RequestBody 该注解常用来处理Content-Type: 不是application/x-www-form-urlencoded编码的内容，例如application/json, application/xml等； 它是通过使用 HandlerAdapter 配置的HttpMessageConverters来解析post data body，然后绑定到相应的bean上的。 因为配置有FormHttpMessageConverter，所以也可以用来处理 application/x-www-form-urlencoded的内容，处理完的结果放在一个MultiValueMap里，这种情况在某些特殊需求下使用，详情查看FormHttpMessageConverter api; 1234@RequestMapping(value = "/something", method = RequestMethod.PUT) public void handle(@RequestBody String body, Writer writer) throws IOException &#123; writer.write(body); &#125; @ResponseBody 作用：该注解用于将Controller的方法返回的对象，通过适当的HttpMessageConverter转换为指定格式后，写入到Response对象的body数据区。 使用时机：返回的数据不是html标签的页面，而是其他某种格式的数据时（如json、xml等）使用； @RequestHeader @RequestHeader 注解，可以把Request请求header部分的值绑定到方法的参数上。 123456789101112131415/*这是一个Request 的header部分：Host localhost:8080 Accept text/html,application/xhtml+xml,application/xml;q=0.9 Accept-Language fr,en-gb;q=0.7,en;q=0.3 Accept-Encoding gzip,deflate Accept-Charset ISO-8859-1,utf-8;q=0.7,*;q=0.7 Keep-Alive 300*/@RequestMapping("/displayHeaderInfo.do") public void displayHeaderInfo(@RequestHeader("Accept-Encoding") String encoding, @RequestHeader("Keep-Alive") long keepAlive) &#123; &#125; 上面的代码，把request header部分的 Accept-Encoding的值，绑定到参数encoding上了， Keep-Alive header的值绑定到参数keepAlive上。 @CookieValue @CookieValue 可以把Request header中关于cookie的值绑定到方法的参数上。 例如有如下Cookie值： JSESSIONID=415A4AC178C59DACE0B2C9CA727CDD84123@RequestMapping("/displayHeaderInfo.do") public void displayHeaderInfo(@CookieValue("JSESSIONID") String cookie) &#123; &#125; 即把JSESSIONID的值绑定到参数cookie上。 @Component 相当于通用的注解，当不知道一些类归到哪个层时使用，但是不建议。 @Repository 用于注解dao层，在daoImpl类上面注解。 &lt; context:component-scan base-package = “” /&gt;浅析 component-scan 默认扫描的注解类型是 @Component，不过，在 @Component 语义基础上细化后的 @Repository, @Service 和 @Controller 也同样可以获得 component-scan 的青睐 有了&lt;context:component-scan&gt;，另一个&lt;context:annotation-config/&gt;标签根本可以移除掉，因为已经被包含进去了 另外&lt;context:annotation-config/&gt;还提供了两个子标签 1.&lt;context:include-filter&gt; //指定扫描的路径 2.&lt;context:exclude-filter&gt; //排除扫描的路径 &lt;context:component-scan&gt; 有一个use-default-filters属性，属性默认为true,表示会扫描指定包下的全部的标有@Component的类，并注册成bean.也就是@Component的子注解@Service,@Repository等。 这种扫描的粒度有点太大，如果你只想扫描指定包下面的Controller或其他内容则设置use-default-filters属性为false，表示不再按照scan指定的包扫描，而是按照&lt;context:include-filter&gt;指定的包扫描，示例： 123&lt;context:component-scan base-package="com.tan" use-default-filters="false"&gt; &lt;context:include-filter type="regex" expression="com.tan.*"/&gt;//注意后面要写.*&lt;/context:component-scan&gt; 当没有设置use-default-filters属性或者属性为true时，表示基于base-package包下指定扫描的具体路径 12345&lt;context:component-scan base-package="com.tan" &gt; &lt;context:include-filter type="regex" expression=".controller.*"/&gt; &lt;context:include-filter type="regex" expression=".service.*"/&gt; &lt;context:include-filter type="regex" expression=".dao.*"/&gt;&lt;/context:component-scan&gt; 效果相当于： 123&lt;context:component-scan base-package="com.tan" &gt; &lt;context:exclude-filter type="regex" expression=".model.*"/&gt;&lt;/context:component-scan&gt;]]></content>
      <categories>
        <category>Spring MVC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 注解]]></title>
    <url>%2F2017%2F09%2F10%2FJava%20%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[注解是java引入的一项非常受欢迎的补充，它提供了一种结构化的，并且具有类型检查能力的新途径，从而使得程序员能够为代码加入元数据，而不会导致代码杂乱且难以阅读。使用注解能够帮助我们避免编写累赘的部署描述文件，以及其他生成的文件。 注解的语法比较简单，除了@符号的使用之外，它基本与java固有的语法一致。但由于java源码中提供的内置注解很少，所以大部分同学对注解都不是很了解，虽然我们都接触过，比如java内置的几种注解： @Override，表示当前的方法定义将覆盖超类中的方法。 @Deprecated，表示当前方法即将废弃，不推荐使用。 @SuppressWarnings，表示忽略编译器的警告信息。 要深入学习注解，我们就必须能定义自己的注解，并使用注解，在定义自己的注解之前，我们就必须要了解Java为我们提供的元注解和相关定义注解的语法。 元注解元注解的作用就是负责注解其他注解。Java5.0定义了4个标准的meta-annotation类型，它们被用来提供对其它 annotation类型作说明。Java5.0定义的元注解： 1.@Target 2.@Retention 3.@Documented 4.@Inherited 这些类型和它们所支持的类在java.lang.annotation包中可以找到。下面我们看一下每个元注解的作用和相应分参数的使用说明。 @Target@Target说明了Annotation所修饰的对象范围：Annotation可被用于 packages、types（类、接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数）。在Annotation类型的声明中使用了target可更加明晰其修饰的目标。 作用：用于描述注解的使用范围（即：被描述的注解可以用在什么地方） 取值(ElementType)有： 1.CONSTRUCTOR:用于描述构造器 2.FIELD:用于描述域 3.LOCAL_VARIABLE:用于描述局部变量 4.METHOD:用于描述方法 5.PACKAGE:用于描述包 6.PARAMETER:用于描述参数 7.TYPE:用于描述类、接口(包括注解类型) 或enum声明 123456789@Target(ElementType.TYPE)public @interface Table &#123; public String tableName() default "className"&#123;&#125;@Target(ElementType.FIELD) public @interface NoDBColumn &#123;&#125; 注解Table 可以用于注解类、接口(包括注解类型) 或enum声明,而注解NoDBColumn仅可用于注解类的成员变量。 @Retention@Retention定义了该Annotation被保留的时间长短：某些Annotation仅出现在源代码中，而被编译器丢弃；而另一些却被编译在class文件中；编译在class文件中的Annotation可能会被虚拟机忽略，而另一些在class被装载时将被读取（请注意并不影响class的执行，因为Annotation与class在使用上是被分离的）。使用这个meta-Annotation可以对 Annotation的“生命周期”限制。 作用：表示需要在什么级别保存该注释信息，用于描述注解的生命周期（即：被描述的注解在什么范围内有效） 取值（RetentionPolicy）有： 1.SOURCE:在源文件中有效（即源文件保留） 2.CLASS:在class文件中有效（即class保留） 3.RUNTIME:在运行时有效（即运行时保留） Retention meta-annotation类型有唯一的value作为成员，它的取值来自java.lang.annotation.RetentionPolicy的枚举类型值。 12345678@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface Column &#123; public String name() default "fieldName"; public String setFuncName() default "setField"; public String getFuncName() default "getField"; public boolean defaultDBValue() default false;&#125; Column注解的的RetentionPolicy的属性值是RUTIME,这样注解处理器可以通过反射，获取到该注解的属性值，从而去做一些运行时的逻辑处理 @Documented@Documented用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。Documented是一个标记注解，没有成员。 123456789@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Column &#123; public String name() default "fieldName"; public String setFuncName() default "setField"; public String getFuncName() default "getField"; public boolean defaultDBValue() default false;&#125; @Inherited@Inherited 元注解是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该class的子类。 注意：@Inherited annotation类型是被标注过的class的子类所继承。类并不从它所实现的接口继承annotation，方法并不从它所重载的方法继承annotation。 当@Inherited annotation类型标注的annotation的Retention是RetentionPolicy.RUNTIME，则反射API增强了这种继承性。如果我们使用java.lang.reflect去查询一个@Inherited annotation类型的annotation时，反射代码检查将展开工作：检查class和其父类，直到发现指定的annotation类型被发现，或者到达类继承结构的顶层。 123456@Inheritedpublic @interface Greeting &#123; public enum FontColor&#123; BLUE,RED,GREEN&#125;; String name(); FontColor fontColor() default FontColor.GREEN;&#125; 自定义注解使用@interface自定义注解时，自动继承了java.lang.annotation.Annotation接口，由编译程序自动完成其他细节。在定义注解时，不能继承其他的注解或接口。@interface用来声明一个注解，其中的每一个方法实际上是声明了一个配置参数。方法的名称就是参数的名称，返回值类型就是参数的类型（返回值类型只能是基本类型、Class、String、enum）。可以通过default来声明参数的默认值。 定义注解格式： public @interface 注解名 {定义体} 注解参数的可支持数据类型： 1.所有基本数据类型（int,float,boolean,byte,double,char,long,short) 2.String类型 3.Class类型 4.enum类型 5.Annotation类型 6.以上所有类型的数组 Annotation类型里面的参数该怎么设定: 第一,只能用public或默认(default)这两个访问权修饰.例如,String value();这里把方法设为default默认类型； 第二,参数成员只能用基本类型byte,short,char,int,long,float,double,boolean八种基本数据类型和 String,Enum,Class,annotations等数据类型,以及这一些类型的数组.例如,String value();这里的参数成员就为String; 第三,如果只有一个参数成员,最好把参数名称设为”value”,后加小括号. 12345678910/*** 自定义注解*/@Target(ElementType.TYPE)@Documented@Retention(RetentionPolicy.RUNTIME)@interface MyAnnotation &#123; String value() default "";&#125; 注解元素的默认值： 注解元素必须有确定的值，要么在定义注解的默认值中指定，要么在使用注解时指定，非基本类型的注解元素的值不可为null。因此, 使用空字符串或0作为默认值是一种常用的做法。这个约束使得处理器很难表现一个元素的存在或缺失的状态，因为每个注解的声明中，所有元素都存在，并且都具有相应的值，为了绕开这个约束，我们只能定义一些特殊的值，例如空字符串或者负数，一次表示某个元素不存在，在定义注解时，这已经成为一个习惯用法。 注解处理注解类使用上了，我们还需要一个注解处理器来解析我们定义的Bean，这样才能将注解转换成我们需要的操作。 Java使用Annotation接口来代表程序元素前面的注解，该接口是所有Annotation类型的父接口。除此之外，Java在java.lang.reflect 包下新增了AnnotatedElement接口，该接口代表程序中可以接受注解的程序元素，该接口主要有如下几个实现类： Class：类定义 Constructor：构造器定义 Field：类的成员变量定义 Method：类的方法定义 Package：类的包定义 java.lang.reflect 包下主要包含一些实现反射功能的工具类，实际上，java.lang.reflect 包所有提供的反射API扩充了读取运行时Annotation信息的能力。当一个Annotation类型被定义为运行时的Annotation后，该注解才能是运行时可见，当class文件被装载时被保存在class文件中的Annotation才会被虚拟机读取。 AnnotatedElement 接口是所有程序元素（Class、Method和Constructor）的父接口，所以程序通过反射获取了某个类的AnnotatedElement对象之后，程序就可以调用该对象的如下四个个方法来访问Annotation信息： &lt;T extends Annotation&gt; T getAnnotation(Class&lt;T&gt; annotationClass): 返回改程序元素上存在的、指定类型的注解，如果该类型注解不存在，则返回null。 Annotation[] getAnnotations():返回该程序元素上存在的所有注解。 boolean is AnnotationPresent(Class&lt;?extends Annotation&gt; annotationClass):判断该程序元素上是否包含指定类型的注解，存在则返回true，否则返回false. Annotation[] getDeclaredAnnotations()：返回直接存在于此元素上的所有注解。与此接口中的其他方法不同，该方法将忽略继承的注解。（如果没有注解直接存在于此元素上，则返回长度为零的一个数组。）该方法的调用者可以随意修改返回的数组；这不会对其他调用者返回的数组产生任何影响。 123456789101112public class TestAnnotation &#123; public static void main(String[] args) &#123; MyAnnotation annotation = annotation.class.getAnnotation(MyAnnotation.class); System.out.println(annotation.value()); &#125; &#125;@MyAnnotation(value = "123")class annotation &#123;&#125; 以上是通过反射获取annotation类的注解，并打印注解中value的值]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令]]></title>
    <url>%2F2017%2F09%2F05%2FGit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[记录一些Git命令 专用名词： Workspace: 工作区 Index/ Stage: 暂存区 Repository: 仓库区（本地仓库） Remote: 远程仓库 图解 新建代码库$ git init # 在当前目录新建一个git代码库 $ git init [project-name] # 新建一个目录，将其初始化为Git仓库 $ git clone [url] # 下载一个项目和它的整个代码历史 配置Git 的设置文件为.gitconfig, 它可以在用户主目录下（全局配置）， 也可以在项目目录下（项目配置）。 $ git config --list # 显示当前的Git配置 $ git config -e [--global] # 编辑Git配置文件 $ git config [--global] user.name &quot;[name]&quot; $ git config [--global] user.email &quot;[email address]&quot; # 设置提交代码时的用户信息 增加/删除文件$ git add [file1] [file2] ... # 添加指定文件到暂存区 $ git add [dir] # 添加指定目录到暂存区，包括子目录 $ git add . # 添加当前目录所有文件到暂存区 $ git add -p # 添加每个变化前，都会要求确认。 对于同一个文件的多处变化，可以多次提交 $ git rm [file1] [file2] # 删除工作区文件，并且将这次删除放入暂存区 $ git rm --cached [file] # 停止追踪指定文件，但该文件会保留在工作区 $ git mv [file-original] [file-renamed] # 改名文件，并且将这个改名放入暂存区 代码提交$ git commit -m [message] # 提交暂存区到仓库区 $ git commit [file1] [file2] -m [message] # 提交暂存区的指定文件到仓库区 $ git commit -a # 提交工作区自上次 commit 之后的变化，直接到仓库区 $ git commit -v # 提交时显示所有的 diff 信息 $ git commit -amend -m [message] # 使用一次新的 commit ，替代上一次提交。如果代码没有任何新变化，则用来改写上一次 commit 的提交信息 $ git commit -amend [file1] [file2] ... # 重做上一次 commit ，并包括指定文件的新变化 分支$ git branch # 列出所有本地分支 $ git branch -r # 列出所有远程分支 $ git branch -a # 列出所有本地分支和远程分支 $ git branch [branch-name] # 新建一个分支，但依然停留在当前分支 $ git branch -b [branch] # 新建一个分支，并切换到该分支 $ git branch [branch] [commit] # 新建一个分支，指向指定commit $ git branch --track [branch] [remote-branch] # 新建一个分支，与指定的远程分支建立追踪关系 $ git checkout [branch-name] # 切换到指定分支，并更新工作区 $ git checkout - # 切换到上一个分支 $ git merge [branch] # 合并指定分支到当前分支 $ git cherry-pick [commit] # 选择一个commit，合并进当前分支 $ git branch -d [branch-name] # 删除分支 $ git push origin -delete [branch-name] $ git branch -dr [remote/branch] # 删除远程分支 标签$ git tag # 列出所有tag $ git tag [tag] # 新建一个tag在当前commit $ git tag [tag] [commit] # 新建一个tag在指定commit $ git tag -d [tag] # 删除本地tag $ git push origin :refs/tags/[tagName] # 删除远程tag $ git show [tag] # 查看tag信息 $ git push [remote] [tag] # 提交指定tag $ git push [remote] --tags # 提交所有tag $ git checkout -b [branch] [tag] # 新建一个分支，指向某个tag 查看信息$ git status # 显示有变更的文件 $ git log # 显示当前分支的版本历史 $ git log --stat # 显示commit历史，以及每次commit发生变更的文件 $ git log -S [keyword] # 搜索提交历史，根据关键词 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --grep feature # 显示某个commit之后的所有变动，其”提交说明”必须符合搜索条件 $ git log --follow [file] $ git whatchange [file] # 显示某个文件的版本历史，包括文件改名 $ git log -p [file] # 显示指定文件相关的每一次diff $ git log -5 --pretty --oneline # 显示过去5次提交 $ git shortlog -sn # 显示所有提交过的用户，按提交次数排序 $ git blame [file] # 显示指定文件是什么人在什么时间修改过 $ git diff # 显示暂存区和工作区的差异 $ git diff --cached [file] # 显示暂存区和上一个commit的差异 $ git diff HEAD # 显示工作区与当前分支最新commit之间的差异 $ git diff [first-branch]...[second-branch] # 显示两次提交之间的差异 $ git diff --shortstat &quot;@{0 day ago}&quot; # 显示今天你写了多少行代码 $ git show [commit] # 显示某次提交的元数据和内容变化 $ git show --name-only [commit] # 显示某次提交发生变化的文件 $ git show [commit]:[filename] # 显示某次提交时，某个文件的内容 $ git reflog # 显示当前分支的最近几次提交 远程同步$ git fetch [remote] # 下载远程仓库的所有变动 $ git remote -v # 显示所有远程仓库 $ git remote show [remote] # 显示某个远程仓库的信息 $ git remote add [shortname] [url] # 增加一个新的远程仓库，并命名 $ git pull [remote] [branch] # 取回远程仓库的变化，并与本地分支合并 $ git push [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] --force # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --all # 推送所有分支到远程仓库 撤销$ git checkout [file] # 恢复暂存区的指定文件到工作区 $ git checkout [commit] [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout . # 恢复暂存区的所有文件到工作区 $ git reset [file] # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset --hard # 重置暂存区与工作区，与上一次commit保持一致 $ git reset [commit] # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset --hard [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --keep [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git revert [commit] # 新建一个commit，用来撤销指定commit。后者的所有变化都将被前者抵消，并且应用到当前分支。 $ git stash $ git stash pop # 暂时将未提交的变化移除，稍后再移入 其他$ git archive # 生成一个可供发布的压缩包]]></content>
      <categories>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于注解形式的Spring AOP实现]]></title>
    <url>%2F2017%2F08%2F14%2F%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E5%BD%A2%E5%BC%8F%E7%9A%84Spring%20AOP%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>Spring MVC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo常用命令笔记]]></title>
    <url>%2F2017%2F06%2F30%2Fhexo%2F</url>
    <content type="text"><![CDATA[hexonpm install hexo -g #安装 npm update hexo -g #升级 hexo init #初始化 简写hexo n &quot;我的博客&quot; == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate #生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy #部署 服务器` hexo server` #Hexo 会监视文件变动并自动更新，您无须重启服务器。 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP hexo clean #清除缓存 网页正常情况下可以忽略此条命令 hexo g #生成静态网页 hexo d #开始部署 监视文件变动hexo generate #使用 Hexo 生成静态文件快速而且简单 hexo generate --watch #监视文件变动 完成后部署两个命令的作用是相同的 hexo generate --deploy hexo deploy --generate hexo deploy -ghexo server -g 草稿hexo publish [layout] &lt;title&gt; 模板hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server） hexo deploy #将.deploy目录部署到GitHub hexo new [layout] &lt;title&gt; hexo new photo &quot;My Gallery&quot; hexo new &quot;Hello World&quot; --lang tw 设置文章摘要以上是文章摘要 &lt;!--more--&gt; 以下是余下全文 写作hexo new page &lt;title&gt; hexo new post &lt;title&gt; ###推送到服务器上 hexo n #写文章 hexo g #生成 hexo d #部署 #可与hexo g合并为 hexo d -g]]></content>
      <categories>
        <category>常用命令</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一个问题]]></title>
    <url>%2F2017%2F06%2F29%2FSecond%2F</url>
    <content type="text"><![CDATA[部署博客后的第一个问题第一次通过 hexo + github 部署博客，并且绑定了个人域名。 但是在每次部署之后使用个人域名访问博客，就会出现 404 界面。 今天在搞定主题之后，直接上传就关了电脑，结果用手机访问博客时发现出现 404 界面。 爬起来开机去 github 的仓库中看了之后发现 在 setting 绑定的域名失效了，又变成了 github 的二级域名 解决方法在百度了之后，绑定域名后DNS解析一定要修改，需要添加记录类型为 CNAME 的解析记录，其中记录值为 yourname.github.io CNAME 是将自己的域名指向你的 github 域名 同时，在本地的 source 文件夹里创建 CNAME 文件 （注意：是CNAME 不是CHAME） 不带任何后缀 里面添加你的域名信息，如： xanxus.xin 不能含有 www 或者 http：// 然后hexo d -g]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>侃侃</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[First]]></title>
    <url>%2F2017%2F06%2F29%2FFirst%2F</url>
    <content type="text"><![CDATA[第一篇文章从今天开始，咱也是有博客的人了，虽然目前能力低，没有什么有价值的文章哈哈哈哈哈哈哈哈哈哈哈 这个博客主要用来记录平时学习的心得体会，遇到的问题以及解决办法 虽然目前遇到的问题很简单，网上很容易找到答案。。。。。。。。 呃。。。。 也没啥要说的，希望这个博客能陪我到毕业甚至工作，也希望这个博客中能记录更多有价值的内容。]]></content>
      <categories>
        <category>测试</category>
      </categories>
      <tags>
        <tag>侃侃</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FirstTest]]></title>
    <url>%2F2017%2F06%2F29%2FFirstTest%2F</url>
    <content type="text"><![CDATA[这是一篇测试用文章 第一次测试 第一次使用hexo搭建博客 #测试 这是一篇测试用文章 第一次测试 第一次使用hexo搭建博客 首次目标，上传至github，并成功。]]></content>
      <tags>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F06%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
